{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elo Merchant Category Recommendation - Outlier detection, ensembling\n",
    "End date: _2019. february 19._<br/>\n",
    "\n",
    "This tutorial notebook is part of a series for [Elo Mechant Category Recommendation](https://www.kaggle.com/c/elo-merchant-category-recommendation) contest organized by Elo, one of the largest payment brands in Brazil. It has built partnerships with merchants in order to offer promotions or discounts to cardholders. The objective of the competition is to identify and serve the most relevant opportunities to individuals, by uncovering signals in customer loyalty. LynxKite does not yet support some of the data preprocessing, thus they need to be done in Python. The input files are available from the [download](https://www.kaggle.com/c/elo-merchant-category-recommendation/data) section of the contest:\n",
    "\n",
    "- **train.csv**,  **test.csv**: list of `card_ids` that can be used for training and testing\n",
    "- **historical_transactions.csv**: contains up to 3 months' worth of transactions for every card at any of the provided `merchant_ids`\n",
    "- **new_merchant_transactions.csv**: contains the transactions at new merchants (`merchant_ids` that this particular `card_id` \n",
    "has not yet visited) over a period of two months\n",
    "- **merchants.csv**: contains aggregate information for each `merchant_id` represented in the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import time\n",
    "import warnings\n",
    "import datetime\n",
    "import calendar\n",
    "import statistics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from datetime import date\n",
    "import matplotlib.pyplot as plt\n",
    "from lightgbm import LGBMClassifier\n",
    "import matplotlib.gridspec as gridspec\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Starting memory usage: {:5.2f} MB'.format(start_mem))\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min >= np.iinfo(np.int8).min and c_max <= np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min >= np.iinfo(np.int16).min and c_max <= np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min >= np.iinfo(np.int32).min and c_max <= np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min >= np.iinfo(np.int64).min and c_max <= np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min >= np.finfo(np.float16).min and c_max <= np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min >= np.finfo(np.float32).min and c_max <= np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Reduced memory usage: {:5.2f} MB ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data preparation\n",
    "### Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting memory usage: 289.84 MB\n",
      "Reduced memory usage: 70.52 MB (75.7% reduction)\n",
      "Starting memory usage: 325.36 MB\n",
      "Reduced memory usage: 96.86 MB (70.2% reduction)\n"
     ]
    }
   ],
   "source": [
    "df_new_trans = pd.read_csv(\"preprocessed/trans_merch_new_agg.csv\")\n",
    "df_new_trans = reduce_mem_usage(df_new_trans)\n",
    "\n",
    "df_hist_trans = pd.read_csv(\"preprocessed/trans_merch_hist_agg.csv\")\n",
    "df_hist_trans = reduce_mem_usage(df_hist_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist_trans.drop(['Unnamed: 0'], inplace=True, axis=1)\n",
    "df_new_trans.drop(['Unnamed: 0'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"preprocessed/train_parsed_outlier_marked.csv\", index_col=\"card_id\")\n",
    "df_test = pd.read_csv(\"preprocessed/test_parsed.csv\", index_col=\"card_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LynxKite export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lk_train = pd.read_csv(\"LynxKite_export/LynxKite_outlier_viral_modeling_train.csv\", index_col=\"card_id\")\n",
    "df_lk_test = pd.read_csv(\"LynxKite_export/LynxKite_outlier_viral_modeling_test.csv\", index_col=\"card_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lk_train.drop(['new_id', 'outlier', 'target', 'type'], inplace=True, axis=1)\n",
    "df_lk_test.drop(['new_id', 'outlier', 'target', 'type'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.merge(df_train, df_lk_train, on='card_id', how='left')\n",
    "df_test = pd.merge(df_test, df_lk_test, on='card_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.merge(df_train, df_hist_trans, on='card_id', how='left')\n",
    "df_test = pd.merge(df_test, df_hist_trans, on='card_id', how='left')\n",
    "\n",
    "df_train = pd.merge(df_train, df_new_trans, on='card_id', how='left')\n",
    "df_test = pd.merge(df_test, df_new_trans, on='card_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting memory usage: 212.97 MB\n",
      "Reduced memory usage: 127.67 MB (40.1% reduction)\n",
      "Starting memory usage: 128.51 MB\n",
      "Reduced memory usage: 81.70 MB (36.4% reduction)\n"
     ]
    }
   ],
   "source": [
    "df_train = reduce_mem_usage(df_train)\n",
    "df_test = reduce_mem_usage(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier selection\n",
    "https://www.kaggle.com/sz8416/6-ways-for-feature-selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marking the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['outlier'] = np.where(df_train['target']<-30, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2,207 marked outliers in the training set.\n"
     ]
    }
   ],
   "source": [
    "print('There are {:,} marked outliers in the training set.'.format(len(df_train[df_train['outlier'] == 1]['outlier'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns2drop = ['card_id', 'target', 'first_active_month', 'viral_outlier_test', 'viral_outlier_train', 'viral_roles',\n",
    "                'hist_avg_purchases_lag3_sum', 'hist_avg_purchases_lag3_mean', 'hist_avg_purchases_lag6_sum',\n",
    "                'hist_avg_purchases_lag6_mean', 'hist_avg_purchases_lag12_sum', 'hist_avg_purchases_lag12_mean',\n",
    "                'viral_outlier_spread_over_iterations', 'hist_transactions_count', 'hist_purchase_year_min',\n",
    "                'new_transactions_count', 'new_authorized_flag_mean']\n",
    "\n",
    "features_train = [c for c in df_train.columns if c not in columns2drop]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_clean = df_train.dropna(how='any', axis=0, subset=features_train)[features_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df):\n",
    "    for c in df.columns:\n",
    "        mean = statistics.mean(df[c])\n",
    "        std = statistics.stdev(df[c])\n",
    "\n",
    "        df.loc[:, c] = (df[c] - mean)/std\n",
    "        print('{}: {:.4f} ({:.4f})'.format(c, mean, std))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 146,616 records in the outlier set.\n",
      "feature_1: 3.0871 (1.1958)\n",
      "feature_2: 1.7319 (0.7497)\n",
      "feature_3: 0.5536 (0.4971)\n",
      "elapsed_days: 361.0683 (285.5164)\n",
      "year: 2016.5552 (0.7572)\n",
      "month: 7.5153 (3.3234)\n",
      "days_feature1: 1152.3708 (1082.4652)\n",
      "days_feature2: 657.3871 (707.0489)\n",
      "days_feature3: 226.1918 (318.1874)\n",
      "number_of_transactions_x: 100.9815 (113.0187)\n",
      "merch_seg_viral_outlier_average_after_iteration_1_most_common: 0.0028 (0.0324)\n",
      "merch_seg_viral_outlier_average_after_iteration_2_most_common: 0.0018 (0.0244)\n",
      "merch_seg_viral_outlier_average_after_iteration_3_most_common: 0.0018 (0.0244)\n",
      "merch_seg_viral_outlier_average_after_iteration_4_most_common: 0.0018 (0.0244)\n",
      "merch_seg_viral_outlier_average_after_iteration_5_most_common: 0.0018 (0.0244)\n",
      "merch_seg_viral_outlier_standard_deviation_after_iteration_1_most_common: 0.0102 (0.0456)\n",
      "merch_seg_viral_outlier_standard_deviation_after_iteration_2_most_common: 0.0075 (0.0353)\n",
      "merch_seg_viral_outlier_standard_deviation_after_iteration_3_most_common: 0.0075 (0.0354)\n",
      "merch_seg_viral_outlier_standard_deviation_after_iteration_4_most_common: 0.0075 (0.0354)\n",
      "merch_seg_viral_outlier_standard_deviation_after_iteration_5_most_common: 0.0075 (0.0354)\n",
      "number_of_transactions_y: 100.9815 (113.0187)\n",
      "viral_outlier_after_iteration_1: 0.0063 (0.0778)\n",
      "viral_outlier_after_iteration_2: 0.0063 (0.0778)\n",
      "viral_outlier_after_iteration_3: 0.0063 (0.0778)\n",
      "viral_outlier_after_iteration_4: 0.0063 (0.0778)\n",
      "viral_outlier_after_iteration_5: 0.0063 (0.0778)\n",
      "hist_authorized_flag_sum: 93.0437 (107.5564)\n",
      "hist_authorized_flag_mean: 0.9031 (0.1024)\n",
      "hist_active_months_lag3_sum: 301.3769 (337.6690)\n",
      "hist_active_months_lag3_mean: 2.9997 (0.0049)\n",
      "hist_active_months_lag6_sum: 602.5968 (675.1491)\n",
      "hist_active_months_lag6_mean: 5.9979 (0.0194)\n",
      "hist_active_months_lag12_sum: 1181.3039 (1327.5562)\n",
      "hist_active_months_lag12_mean: 11.7381 (0.3127)\n",
      "hist_avg_sales_lag3_sum: 13066.7265 (151294.6141)\n",
      "hist_avg_sales_lag3_mean: 137.1945 (2047.9579)\n",
      "hist_avg_sales_lag6_sum: 12369.0990 (142215.5033)\n",
      "hist_avg_sales_lag6_mean: 130.2733 (1930.0888)\n",
      "hist_avg_sales_lag12_sum: 11461.8815 (138638.4758)\n",
      "hist_avg_sales_lag12_mean: 120.6949 (1864.9345)\n",
      "hist_card_id_size: 100.9815 (113.0187)\n",
      "hist_category_1_trans_sum: 5.8569 (17.9174)\n",
      "hist_category_1_trans_mean: 0.0720 (0.1460)\n",
      "hist_category_1_merch_sum: 12.6617 (21.6057)\n",
      "hist_category_1_merch_mean: 0.1450 (0.1597)\n",
      "hist_category_2_trans_sum: 204.8853 (314.3052)\n",
      "hist_category_2_trans_mean: 2.1663 (1.3707)\n",
      "hist_category_2_merch_sum: 197.0231 (307.7104)\n",
      "hist_category_2_merch_mean: 2.2518 (1.4796)\n",
      "hist_category_3_sum: 52.5236 (90.7269)\n",
      "hist_category_3_mean: 0.6302 (0.6043)\n",
      "hist_category_4_sum: 51.8937 (84.9852)\n",
      "hist_category_4_mean: 0.4964 (0.3768)\n",
      "hist_city_id_trans_nunique: 5.3885 (3.7166)\n",
      "hist_city_id_merch_nunique: 3.9484 (2.7050)\n",
      "hist_installments_sum: 63.2212 (108.4569)\n",
      "hist_installments_median: 0.5849 (0.7059)\n",
      "hist_installments_mean: 0.8080 (1.0466)\n",
      "hist_installments_max: 4.3116 (24.0131)\n",
      "hist_installments_min: -0.0022 (0.7149)\n",
      "hist_installments_std: 0.7612 (3.0433)\n",
      "hist_merchant_id_nunique: 38.6340 (32.7522)\n",
      "hist_merchant_category_id_trans_nunique: 20.2834 (11.7099)\n",
      "hist_merchant_category_id_merch_nunique: 19.4568 (11.0881)\n",
      "hist_merchant_group_id_nunique: 26.4779 (22.5086)\n",
      "hist_month_lag_max: -0.1271 (0.5697)\n",
      "hist_month_lag_min: -7.5633 (3.8855)\n",
      "hist_month_lag_mean: -3.6199 (2.0831)\n",
      "hist_month_lag_var: 6.7578 (6.0569)\n",
      "hist_most_recent_sales_range_sum: 230.0839 (267.0934)\n",
      "hist_most_recent_sales_range_mean: 2.2852 (0.5207)\n",
      "hist_most_recent_sales_range_max: 3.9327 (0.2872)\n",
      "hist_most_recent_sales_range_min: 0.0960 (0.3580)\n",
      "hist_most_recent_sales_range_std: 1.2372 (0.2305)\n",
      "hist_most_recent_purchases_range_sum: 238.1722 (280.5880)\n",
      "hist_most_recent_purchases_range_mean: 2.3244 (0.5239)\n",
      "hist_most_recent_purchases_range_max: 3.9303 (0.2971)\n",
      "hist_most_recent_purchases_range_min: 0.1027 (0.3607)\n",
      "hist_most_recent_purchases_range_std: 1.2232 (0.2271)\n",
      "hist_numerical_1_mean: 5.1108 (8.5089)\n",
      "hist_numerical_1_median: 0.3787 (4.4539)\n",
      "hist_numerical_1_max: 57.8977 (65.2794)\n",
      "hist_numerical_1_min: -0.0537 (0.3717)\n",
      "hist_numerical_1_std: 12.4972 (15.6889)\n",
      "hist_numerical_2_mean: 4.9959 (8.3954)\n",
      "hist_numerical_2_median: 0.3183 (4.4072)\n",
      "hist_numerical_2_max: 57.2689 (64.6392)\n",
      "hist_numerical_2_min: -0.0541 (0.3662)\n",
      "hist_numerical_2_std: 12.3782 (15.5490)\n",
      "hist_number_of_transactions_mean: 66009.6993 (71870.8124)\n",
      "hist_number_of_transactions_median: 8857.7136 (53556.4197)\n",
      "hist_number_of_transactions_max: 826185.5829 (456979.0659)\n",
      "hist_number_of_transactions_min: 29.2214 (505.2259)\n",
      "hist_number_of_transactions_std: 181585.9474 (126279.6635)\n",
      "hist_state_id_trans_nunique: 2.8794 (1.5853)\n",
      "hist_state_id_merch_nunique: 2.6344 (1.2545)\n",
      "hist_subsector_id_trans_nunique: 12.4158 (5.0656)\n",
      "hist_subsector_id_merch_nunique: 12.4340 (5.0462)\n",
      "hist_purchase_amount_sum: 17.4285 (15752.9779)\n",
      "hist_purchase_amount_mean: 3.2516 (1308.2605)\n",
      "hist_purchase_amount_max: 77.0016 (15752.2677)\n",
      "hist_purchase_amount_min: -0.7333 (0.0441)\n",
      "hist_purchase_amount_std: 15.3408 (4533.1719)\n",
      "hist_purchase_year_mean: 2017.1319 (0.3383)\n",
      "hist_purchase_year_median: 2017.1319 (0.3383)\n",
      "hist_purchase_year_max: 2017.7619 (0.4259)\n",
      "hist_purchase_year_std: 0.3061 (0.1886)\n",
      "hist_purchase_year_nunique: 1.7619 (0.4259)\n",
      "hist_purchase_month_mean: 6.5170 (1.8490)\n",
      "hist_purchase_month_median: 6.7254 (3.0051)\n",
      "hist_purchase_month_max: 11.2182 (1.8833)\n",
      "hist_purchase_month_min: 1.5527 (1.6560)\n",
      "hist_purchase_month_std: 3.4613 (1.1855)\n",
      "hist_purchase_month_nunique: 7.3549 (3.1376)\n",
      "hist_purchase_day_mean: 15.9686 (2.5654)\n",
      "hist_purchase_day_median: 16.0331 (3.9707)\n",
      "hist_purchase_day_max: 29.8787 (2.1969)\n",
      "hist_purchase_day_min: 2.0132 (2.2530)\n",
      "hist_purchase_day_std: 8.2787 (1.4055)\n",
      "hist_purchase_day_nunique: 21.7163 (7.9074)\n",
      "hist_purchase_hour_mean: 14.0831 (1.4924)\n",
      "hist_purchase_hour_median: 14.5939 (1.9657)\n",
      "hist_purchase_hour_max: 22.0767 (1.5045)\n",
      "hist_purchase_hour_min: 1.9158 (3.5147)\n",
      "hist_purchase_hour_std: 5.0899 (1.3066)\n",
      "hist_purchase_hour_nunique: 15.6561 (4.6624)\n",
      "hist_purchase_weekofyear_mean: 26.5151 (8.0253)\n",
      "hist_purchase_weekofyear_median: 27.3399 (12.9275)\n",
      "hist_purchase_weekofyear_max: 48.2102 (8.0694)\n",
      "hist_purchase_weekofyear_min: 4.0575 (7.5041)\n",
      "hist_purchase_weekofyear_std: 15.0596 (5.1387)\n",
      "hist_purchase_weekofyear_nunique: 21.4732 (12.5779)\n",
      "hist_purchase_dayofweek_mean: 3.0262 (0.5356)\n",
      "hist_purchase_dayofweek_median: 3.1333 (0.8608)\n",
      "hist_purchase_dayofweek_max: 5.8638 (0.4290)\n",
      "hist_purchase_dayofweek_min: 0.0713 (0.3342)\n",
      "hist_purchase_dayofweek_std: 1.8446 (0.2387)\n",
      "hist_purchase_dayofweek_nunique: 6.6317 (0.8306)\n",
      "hist_purchase_quarter_mean: 2.5173 (0.5908)\n",
      "hist_purchase_quarter_median: 2.5812 (1.0286)\n",
      "hist_purchase_quarter_max: 3.8179 (0.5438)\n",
      "hist_purchase_quarter_min: 1.1325 (0.4744)\n",
      "hist_purchase_quarter_std: 1.0739 (0.3434)\n",
      "hist_purchase_part_of_month_mean: 1.1037 (0.2440)\n",
      "hist_purchase_part_of_month_median: 1.1177 (0.4629)\n",
      "hist_purchase_weekend_sum: 28.4414 (34.3729)\n",
      "hist_purchase_weekend_mean: 0.2806 (0.1340)\n",
      "new_authorized_flag_sum: 7.9689 (6.8202)\n",
      "new_active_months_lag3_sum: 23.6111 (20.3333)\n",
      "new_active_months_lag3_mean: 2.9998 (0.0067)\n",
      "new_active_months_lag6_sum: 47.1566 (40.6065)\n",
      "new_active_months_lag6_mean: 5.9922 (0.0545)\n",
      "new_active_months_lag12_sum: 92.7752 (80.3013)\n",
      "new_active_months_lag12_mean: 11.7626 (0.4877)\n",
      "new_avg_sales_lag3_sum: 365.2557 (17254.9316)\n",
      "new_avg_sales_lag3_mean: 41.1912 (2424.4511)\n",
      "new_avg_sales_lag6_sum: 363.3568 (16747.8102)\n",
      "new_avg_sales_lag6_mean: 39.6240 (2214.7283)\n",
      "new_avg_sales_lag12_sum: 346.0214 (17025.0475)\n",
      "new_avg_sales_lag12_mean: 36.4590 (1997.2018)\n",
      "new_avg_purchases_lag3_sum: 36.9255 (1241.2535)\n",
      "new_avg_purchases_lag3_mean: 4.4141 (174.9414)\n",
      "new_avg_purchases_lag6_sum: 66.0338 (1136.8817)\n",
      "new_avg_purchases_lag6_mean: 8.6830 (161.1070)\n",
      "new_avg_purchases_lag12_sum: 69.0156 (1030.7770)\n",
      "new_avg_purchases_lag12_mean: 9.1674 (146.9691)\n",
      "new_card_id_size: 7.9689 (6.8202)\n",
      "new_category_1_trans_sum: 0.2223 (0.6012)\n",
      "new_category_1_trans_mean: 0.0325 (0.0953)\n",
      "new_category_1_merch_sum: 0.6712 (0.9933)\n",
      "new_category_1_merch_mean: 0.0968 (0.1482)\n",
      "new_category_2_trans_sum: 16.6771 (20.2270)\n",
      "new_category_2_trans_mean: 2.1810 (1.3982)\n",
      "new_category_2_merch_sum: 15.9835 (19.8735)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_category_2_merch_mean: 2.2377 (1.4758)\n",
      "new_category_3_sum: 4.5775 (6.9506)\n",
      "new_category_3_mean: 0.6156 (0.6155)\n",
      "new_category_4_sum: 3.9364 (5.1460)\n",
      "new_category_4_mean: 0.4770 (0.3884)\n",
      "new_city_id_trans_nunique: 2.5839 (1.7275)\n",
      "new_city_id_merch_nunique: 2.3113 (1.3520)\n",
      "new_installments_sum: 5.3500 (8.7879)\n",
      "new_installments_median: 0.5993 (0.7816)\n",
      "new_installments_mean: 0.6973 (0.9062)\n",
      "new_installments_max: 1.5637 (3.5770)\n",
      "new_installments_min: 0.2152 (0.7373)\n",
      "new_installments_std: 0.5075 (1.0764)\n",
      "new_merchant_id_nunique: 7.8677 (6.7754)\n",
      "new_merchant_category_id_trans_nunique: 6.2233 (4.1856)\n",
      "new_merchant_category_id_merch_nunique: 6.1393 (4.1487)\n",
      "new_merchant_group_id_nunique: 6.2793 (5.2163)\n",
      "new_month_lag_max: 1.8792 (0.3258)\n",
      "new_month_lag_min: 1.0982 (0.2976)\n",
      "new_month_lag_mean: 1.4756 (0.2884)\n",
      "new_month_lag_var: 0.2096 (0.1335)\n",
      "new_most_recent_sales_range_sum: 15.9722 (13.9074)\n",
      "new_most_recent_sales_range_mean: 2.0686 (0.6674)\n",
      "new_most_recent_sales_range_max: 3.4746 (0.8204)\n",
      "new_most_recent_sales_range_min: 0.6644 (0.8607)\n",
      "new_most_recent_sales_range_std: 1.1671 (0.4581)\n",
      "new_most_recent_purchases_range_sum: 16.3153 (14.3525)\n",
      "new_most_recent_purchases_range_mean: 2.0970 (0.6683)\n",
      "new_most_recent_purchases_range_max: 3.4822 (0.8300)\n",
      "new_most_recent_purchases_range_min: 0.7332 (0.8454)\n",
      "new_most_recent_purchases_range_std: 1.1435 (0.4514)\n",
      "new_numerical_1_mean: 3.6585 (8.4425)\n",
      "new_numerical_1_median: 0.9135 (5.7005)\n",
      "new_numerical_1_max: 19.9359 (39.2105)\n",
      "new_numerical_1_min: 0.0188 (1.4507)\n",
      "new_numerical_1_std: 7.3047 (14.7373)\n",
      "new_numerical_2_mean: 3.5716 (8.3451)\n",
      "new_numerical_2_median: 0.8592 (5.6377)\n",
      "new_numerical_2_max: 19.6480 (38.8213)\n",
      "new_numerical_2_min: 0.0114 (1.4291)\n",
      "new_numerical_2_std: 7.2068 (14.6038)\n",
      "new_number_of_transactions_mean: 28812.6147 (74747.3174)\n",
      "new_number_of_transactions_median: 7664.1854 (50959.1535)\n",
      "new_number_of_transactions_max: 148609.0381 (314338.9939)\n",
      "new_number_of_transactions_min: 264.5310 (2649.8658)\n",
      "new_number_of_transactions_std: 58806.8679 (135688.9659)\n",
      "new_state_id_trans_nunique: 1.6969 (0.9187)\n",
      "new_state_id_merch_nunique: 1.7123 (0.8307)\n",
      "new_subsector_id_trans_nunique: 5.1528 (2.9218)\n",
      "new_subsector_id_merch_nunique: 5.1168 (2.9233)\n",
      "new_purchase_amount_sum: -4.4389 (4.5236)\n",
      "new_purchase_amount_mean: -0.5477 (0.3841)\n",
      "new_purchase_amount_max: -0.0814 (1.5963)\n",
      "new_purchase_amount_min: -0.7044 (0.1095)\n",
      "new_purchase_amount_std: 0.2274 (0.5755)\n",
      "new_purchase_year_mean: 2017.8528 (0.3544)\n",
      "new_purchase_year_median: 2017.8528 (0.3544)\n",
      "new_purchase_year_max: 2017.8658 (0.3408)\n",
      "new_purchase_year_min: 2017.8404 (0.3663)\n",
      "new_purchase_year_std: 0.0128 (0.0805)\n",
      "new_purchase_year_nunique: 1.0255 (0.1576)\n",
      "new_purchase_month_mean: 4.1005 (2.2428)\n",
      "new_purchase_month_median: 4.0987 (2.4020)\n",
      "new_purchase_month_max: 4.6176 (2.4675)\n",
      "new_purchase_month_min: 3.5818 (2.2096)\n",
      "new_purchase_month_std: 0.5280 (0.8534)\n",
      "new_purchase_month_nunique: 1.7810 (0.4136)\n",
      "new_purchase_day_mean: 15.6908 (5.1074)\n",
      "new_purchase_day_median: 15.6802 (6.4202)\n",
      "new_purchase_day_max: 24.5753 (6.4923)\n",
      "new_purchase_day_min: 6.8254 (6.1816)\n",
      "new_purchase_day_std: 7.2386 (3.5164)\n",
      "new_purchase_day_nunique: 5.7114 (3.8105)\n",
      "new_purchase_hour_mean: 13.5057 (2.4386)\n",
      "new_purchase_hour_median: 13.6086 (2.8751)\n",
      "new_purchase_hour_max: 18.5057 (3.3206)\n",
      "new_purchase_hour_min: 8.0443 (4.0738)\n",
      "new_purchase_hour_std: 4.0248 (1.9222)\n",
      "new_purchase_hour_nunique: 5.5492 (3.2616)\n",
      "new_purchase_weekofyear_mean: 15.9274 (9.7561)\n",
      "new_purchase_weekofyear_median: 15.9646 (10.3426)\n",
      "new_purchase_weekofyear_max: 18.9600 (10.7798)\n",
      "new_purchase_weekofyear_min: 12.8309 (9.6507)\n",
      "new_purchase_weekofyear_std: 2.6365 (3.6534)\n",
      "new_purchase_weekofyear_nunique: 3.9454 (1.9790)\n",
      "new_purchase_dayofweek_mean: 3.0989 (1.0268)\n",
      "new_purchase_dayofweek_median: 3.1908 (1.3315)\n",
      "new_purchase_dayofweek_max: 5.0338 (1.2041)\n",
      "new_purchase_dayofweek_min: 0.9728 (1.3333)\n",
      "new_purchase_dayofweek_std: 1.6801 (0.7018)\n",
      "new_purchase_dayofweek_nunique: 3.8461 (1.6496)\n",
      "new_purchase_quarter_mean: 1.6795 (0.7682)\n",
      "new_purchase_quarter_median: 1.6689 (0.8602)\n",
      "new_purchase_quarter_max: 2.0197 (0.7953)\n",
      "new_purchase_quarter_min: 1.3550 (0.8093)\n",
      "new_purchase_quarter_std: 0.3400 (0.3200)\n",
      "new_purchase_part_of_month_mean: 1.0726 (0.4757)\n",
      "new_purchase_part_of_month_median: 1.0999 (0.6622)\n",
      "new_purchase_weekend_sum: 2.4629 (2.8596)\n",
      "new_purchase_weekend_mean: 0.3003 (0.2486)\n",
      "There are 274 features and 146,616 items in the training set.\n"
     ]
    }
   ],
   "source": [
    "y = df_train_clean['outlier']\n",
    "print('There are {:,} records in the outlier set.'.format(len(y)))\n",
    "\n",
    "df_train_clean.drop(['outlier'], axis=1, inplace=True)\n",
    "X = normalize(df_train_clean)\n",
    "print('There are {:,} features and {:,} items in the training set.'.format(X.shape[1], X.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((146616, 274), (146616,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature_1                                                                   0\n",
       "feature_2                                                                   0\n",
       "feature_3                                                                   0\n",
       "elapsed_days                                                                0\n",
       "year                                                                        0\n",
       "month                                                                       0\n",
       "days_feature1                                                               0\n",
       "days_feature2                                                               0\n",
       "days_feature3                                                               0\n",
       "number_of_transactions_x                                                    0\n",
       "merch_seg_viral_outlier_average_after_iteration_1_most_common               0\n",
       "merch_seg_viral_outlier_average_after_iteration_2_most_common               0\n",
       "merch_seg_viral_outlier_average_after_iteration_3_most_common               0\n",
       "merch_seg_viral_outlier_average_after_iteration_4_most_common               0\n",
       "merch_seg_viral_outlier_average_after_iteration_5_most_common               0\n",
       "merch_seg_viral_outlier_standard_deviation_after_iteration_1_most_common    0\n",
       "merch_seg_viral_outlier_standard_deviation_after_iteration_2_most_common    0\n",
       "merch_seg_viral_outlier_standard_deviation_after_iteration_3_most_common    0\n",
       "merch_seg_viral_outlier_standard_deviation_after_iteration_4_most_common    0\n",
       "merch_seg_viral_outlier_standard_deviation_after_iteration_5_most_common    0\n",
       "number_of_transactions_y                                                    0\n",
       "viral_outlier_after_iteration_1                                             0\n",
       "viral_outlier_after_iteration_2                                             0\n",
       "viral_outlier_after_iteration_3                                             0\n",
       "viral_outlier_after_iteration_4                                             0\n",
       "viral_outlier_after_iteration_5                                             0\n",
       "hist_authorized_flag_sum                                                    0\n",
       "hist_authorized_flag_mean                                                   0\n",
       "hist_active_months_lag3_sum                                                 0\n",
       "hist_active_months_lag3_mean                                                0\n",
       "                                                                           ..\n",
       "new_purchase_day_min                                                        0\n",
       "new_purchase_day_std                                                        0\n",
       "new_purchase_day_nunique                                                    0\n",
       "new_purchase_hour_mean                                                      0\n",
       "new_purchase_hour_median                                                    0\n",
       "new_purchase_hour_max                                                       0\n",
       "new_purchase_hour_min                                                       0\n",
       "new_purchase_hour_std                                                       0\n",
       "new_purchase_hour_nunique                                                   0\n",
       "new_purchase_weekofyear_mean                                                0\n",
       "new_purchase_weekofyear_median                                              0\n",
       "new_purchase_weekofyear_max                                                 0\n",
       "new_purchase_weekofyear_min                                                 0\n",
       "new_purchase_weekofyear_std                                                 0\n",
       "new_purchase_weekofyear_nunique                                             0\n",
       "new_purchase_dayofweek_mean                                                 0\n",
       "new_purchase_dayofweek_median                                               0\n",
       "new_purchase_dayofweek_max                                                  0\n",
       "new_purchase_dayofweek_min                                                  0\n",
       "new_purchase_dayofweek_std                                                  0\n",
       "new_purchase_dayofweek_nunique                                              0\n",
       "new_purchase_quarter_mean                                                   0\n",
       "new_purchase_quarter_median                                                 0\n",
       "new_purchase_quarter_max                                                    0\n",
       "new_purchase_quarter_min                                                    0\n",
       "new_purchase_quarter_std                                                    0\n",
       "new_purchase_part_of_month_mean                                             0\n",
       "new_purchase_part_of_month_median                                           0\n",
       "new_purchase_weekend_sum                                                    0\n",
       "new_purchase_weekend_mean                                                   0\n",
       "Length: 274, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pearson correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cor_selector(X, y, limit=100):\n",
    "    cor_list = []\n",
    "    for i in X.columns.tolist():\n",
    "        cor = np.corrcoef(X[i], y)[0, 1]\n",
    "        cor_list.append(cor)\n",
    "\n",
    "    cor_list = [0 if np.isnan(i) else i for i in cor_list]\n",
    "    cor_feature = X.iloc[:,np.argsort(np.abs(cor_list))[-limit:]].columns.tolist()\n",
    "    cor_support = [True if i in cor_feature else False for i in X.columns.tolist()]\n",
    "    return cor_support, cor_feature, cor_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 selected features\n"
     ]
    }
   ],
   "source": [
    "cor_support, cor_feature, cor_value = cor_selector(X, y)\n",
    "print(str(len(cor_feature)), 'selected features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chi-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype float16, float32, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SelectKBest(k=100, score_func=<function chi2 at 0x7f94891f59d8>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "X_norm = MinMaxScaler().fit_transform(X)\n",
    "chi_selector = SelectKBest(chi2, k=100)\n",
    "chi_selector.fit(X_norm, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 selected features\n"
     ]
    }
   ],
   "source": [
    "chi_support = chi_selector.get_support()\n",
    "chi_feature = X.loc[:,chi_support].columns.tolist()\n",
    "print(str(len(chi_feature)), 'selected features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 274 features.\n",
      "Fitting estimator with 264 features.\n",
      "Fitting estimator with 254 features.\n",
      "Fitting estimator with 244 features.\n",
      "Fitting estimator with 234 features.\n",
      "Fitting estimator with 224 features.\n",
      "Fitting estimator with 214 features.\n",
      "Fitting estimator with 204 features.\n",
      "Fitting estimator with 194 features.\n",
      "Fitting estimator with 184 features.\n",
      "Fitting estimator with 174 features.\n",
      "Fitting estimator with 164 features.\n",
      "Fitting estimator with 154 features.\n",
      "Fitting estimator with 144 features.\n",
      "Fitting estimator with 134 features.\n",
      "Fitting estimator with 124 features.\n",
      "Fitting estimator with 114 features.\n",
      "Fitting estimator with 104 features.\n",
      "Fitting estimator with 94 features.\n",
      "Fitting estimator with 84 features.\n",
      "Fitting estimator with 74 features.\n",
      "Fitting estimator with 64 features.\n",
      "Fitting estimator with 54 features.\n",
      "Fitting estimator with 44 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 14 features.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RFE(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "  n_features_to_select=5, step=10, verbose=5)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "rfe_selector = RFE(estimator=LogisticRegression(), n_features_to_select=5, step=10, verbose=5)\n",
    "rfe_selector.fit(X_norm, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 selected features\n"
     ]
    }
   ],
   "source": [
    "rfe_support = rfe_selector.get_support()\n",
    "rfe_feature = X.loc[:,rfe_support].columns.tolist()\n",
    "print(str(len(rfe_feature)), 'selected features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l1', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "        max_features=None, norm_order=1, prefit=False,\n",
       "        threshold='1.25*median')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "embeded_lr_selector = SelectFromModel(LogisticRegression(penalty=\"l1\"), '1.25*median')\n",
    "embeded_lr_selector.fit(X_norm, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274 selected features\n"
     ]
    }
   ],
   "source": [
    "embeded_lr_support = embeded_lr_selector.get_support()\n",
    "embeded_lr_feature = X.loc[:,embeded_lr_support].columns.tolist()\n",
    "print(str(len(embeded_lr_feature)), 'selected features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=5, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "        max_features=None, norm_order=1, prefit=False,\n",
       "        threshold='1.25*median')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeded_rf_selector = SelectFromModel(RandomForestClassifier(n_estimators=5), threshold='1.25*median')\n",
    "embeded_rf_selector.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112 selected features\n"
     ]
    }
   ],
   "source": [
    "embeded_rf_support = embeded_rf_selector.get_support()\n",
    "embeded_rf_feature = X.loc[:,embeded_rf_support].columns.tolist()\n",
    "print(str(len(embeded_rf_feature)), 'selected features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.2,\n",
       "        importance_type='split', learning_rate=0.05, max_depth=-1,\n",
       "        min_child_samples=20, min_child_weight=40, min_split_gain=0.01,\n",
       "        n_estimators=500, n_jobs=-1, num_leaves=32, objective=None,\n",
       "        random_state=None, reg_alpha=3, reg_lambda=1, silent=True,\n",
       "        subsample=1.0, subsample_for_bin=200000, subsample_freq=0),\n",
       "        max_features=None, norm_order=1, prefit=False,\n",
       "        threshold='1.25*median')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbc=LGBMClassifier(n_estimators=500, learning_rate=0.05, num_leaves=32, colsample_bytree=0.2,\n",
    "            reg_alpha=3, reg_lambda=1, min_split_gain=0.01, min_child_weight=40)\n",
    "\n",
    "embeded_lgb_selector = SelectFromModel(lgbc, threshold='1.25*median')\n",
    "embeded_lgb_selector.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109 selected features\n"
     ]
    }
   ],
   "source": [
    "embeded_lgb_support = embeded_lgb_selector.get_support()\n",
    "embeded_lgb_feature = X.loc[:,embeded_lgb_support].columns.tolist()\n",
    "print(str(len(embeded_lgb_feature)), 'selected features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Chi-2</th>\n",
       "      <th>RFE</th>\n",
       "      <th>Logistics</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>LightGBM</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>viral_outlier_after_iteration_5</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>viral_outlier_after_iteration_4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>new_purchase_weekofyear_nunique</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>viral_outlier_after_iteration_3</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>viral_outlier_after_iteration_2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>viral_outlier_after_iteration_1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>new_purchase_weekofyear_mean</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>new_purchase_weekofyear_max</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>new_purchase_quarter_max</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>new_purchase_month_max</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>new_purchase_day_std</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>new_purchase_day_max</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>new_month_lag_mean</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>new_merchant_group_id_nunique</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>merch_seg_viral_outlier_standard_deviation_aft...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>merch_seg_viral_outlier_standard_deviation_aft...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>merch_seg_viral_outlier_standard_deviation_aft...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>merch_seg_viral_outlier_average_after_iteratio...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>merch_seg_viral_outlier_average_after_iteratio...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>merch_seg_viral_outlier_average_after_iteratio...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>merch_seg_viral_outlier_average_after_iteratio...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>hist_purchase_year_std</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>hist_purchase_weekofyear_std</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>hist_purchase_weekofyear_min</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>hist_purchase_month_std</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>hist_category_3_sum</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>hist_category_1_trans_sum</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>hist_category_1_merch_sum</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>hist_category_1_merch_mean</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>new_subsector_id_trans_nunique</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>new_purchase_year_min</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>new_purchase_weekofyear_min</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>new_purchase_weekofyear_median</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>new_purchase_weekend_sum</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>new_purchase_quarter_median</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>new_purchase_month_median</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>new_purchase_month_mean</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>new_purchase_day_median</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>new_purchase_day_mean</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>new_number_of_transactions_median</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>new_number_of_transactions_mean</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>new_month_lag_max</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>new_merchant_category_id_trans_nunique</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>new_merchant_category_id_merch_nunique</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>new_category_2_merch_sum</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>new_category_1_trans_mean</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>new_category_1_merch_mean</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>new_authorized_flag_sum</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>new_active_months_lag3_sum</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>new_active_months_lag12_sum</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              feature  Pearson  Chi-2    RFE  \\\n",
       "1                     viral_outlier_after_iteration_5     True   True   True   \n",
       "2                     viral_outlier_after_iteration_4     True   True   True   \n",
       "3                     new_purchase_weekofyear_nunique     True   True   True   \n",
       "4                     viral_outlier_after_iteration_3     True   True  False   \n",
       "5                     viral_outlier_after_iteration_2     True   True  False   \n",
       "6                     viral_outlier_after_iteration_1     True   True  False   \n",
       "7                        new_purchase_weekofyear_mean     True   True  False   \n",
       "8                         new_purchase_weekofyear_max     True   True  False   \n",
       "9                            new_purchase_quarter_max     True   True  False   \n",
       "10                             new_purchase_month_max     True   True  False   \n",
       "11                               new_purchase_day_std     True   True  False   \n",
       "12                               new_purchase_day_max     True   True  False   \n",
       "13                                 new_month_lag_mean     True   True  False   \n",
       "14                      new_merchant_group_id_nunique     True   True  False   \n",
       "15  merch_seg_viral_outlier_standard_deviation_aft...     True   True  False   \n",
       "16  merch_seg_viral_outlier_standard_deviation_aft...     True   True  False   \n",
       "17  merch_seg_viral_outlier_standard_deviation_aft...     True   True  False   \n",
       "18  merch_seg_viral_outlier_average_after_iteratio...     True   True  False   \n",
       "19  merch_seg_viral_outlier_average_after_iteratio...     True   True  False   \n",
       "20  merch_seg_viral_outlier_average_after_iteratio...     True   True  False   \n",
       "21  merch_seg_viral_outlier_average_after_iteratio...     True   True  False   \n",
       "22                             hist_purchase_year_std     True   True   True   \n",
       "23                       hist_purchase_weekofyear_std     True   True  False   \n",
       "24                       hist_purchase_weekofyear_min     True   True  False   \n",
       "25                            hist_purchase_month_std     True   True  False   \n",
       "26                                hist_category_3_sum     True   True  False   \n",
       "27                          hist_category_1_trans_sum     True   True  False   \n",
       "28                          hist_category_1_merch_sum     True   True  False   \n",
       "29                         hist_category_1_merch_mean     True   True  False   \n",
       "30                     new_subsector_id_trans_nunique     True   True  False   \n",
       "31                              new_purchase_year_min     True   True  False   \n",
       "32                        new_purchase_weekofyear_min     True   True  False   \n",
       "33                     new_purchase_weekofyear_median     True   True  False   \n",
       "34                           new_purchase_weekend_sum     True   True  False   \n",
       "35                        new_purchase_quarter_median     True   True  False   \n",
       "36                          new_purchase_month_median     True   True  False   \n",
       "37                            new_purchase_month_mean     True   True  False   \n",
       "38                            new_purchase_day_median    False   True  False   \n",
       "39                              new_purchase_day_mean     True  False  False   \n",
       "40                  new_number_of_transactions_median    False   True  False   \n",
       "41                    new_number_of_transactions_mean    False   True  False   \n",
       "42                                  new_month_lag_max     True   True  False   \n",
       "43             new_merchant_category_id_trans_nunique     True   True  False   \n",
       "44             new_merchant_category_id_merch_nunique     True   True  False   \n",
       "45                           new_category_2_merch_sum     True  False  False   \n",
       "46                          new_category_1_trans_mean     True   True  False   \n",
       "47                          new_category_1_merch_mean     True   True  False   \n",
       "48                            new_authorized_flag_sum     True   True  False   \n",
       "49                         new_active_months_lag3_sum     True   True  False   \n",
       "50                        new_active_months_lag12_sum     True   True  False   \n",
       "\n",
       "    Logistics  Random Forest  LightGBM  total  \n",
       "1        True           True      True      6  \n",
       "2        True           True      True      6  \n",
       "3        True           True      True      6  \n",
       "4        True           True      True      5  \n",
       "5        True           True      True      5  \n",
       "6        True           True      True      5  \n",
       "7        True           True      True      5  \n",
       "8        True           True      True      5  \n",
       "9        True           True      True      5  \n",
       "10       True           True      True      5  \n",
       "11       True           True      True      5  \n",
       "12       True           True      True      5  \n",
       "13       True           True      True      5  \n",
       "14       True           True      True      5  \n",
       "15       True           True      True      5  \n",
       "16       True           True      True      5  \n",
       "17       True           True      True      5  \n",
       "18       True           True      True      5  \n",
       "19       True           True      True      5  \n",
       "20       True           True      True      5  \n",
       "21       True           True      True      5  \n",
       "22       True          False      True      5  \n",
       "23       True           True      True      5  \n",
       "24       True           True      True      5  \n",
       "25       True           True      True      5  \n",
       "26       True           True      True      5  \n",
       "27       True           True      True      5  \n",
       "28       True           True      True      5  \n",
       "29       True           True      True      5  \n",
       "30       True          False      True      4  \n",
       "31       True           True     False      4  \n",
       "32       True          False      True      4  \n",
       "33       True          False      True      4  \n",
       "34       True           True     False      4  \n",
       "35       True           True     False      4  \n",
       "36       True           True     False      4  \n",
       "37       True          False      True      4  \n",
       "38       True           True      True      4  \n",
       "39       True           True      True      4  \n",
       "40       True           True      True      4  \n",
       "41       True           True      True      4  \n",
       "42       True          False      True      4  \n",
       "43       True           True     False      4  \n",
       "44       True           True     False      4  \n",
       "45       True           True      True      4  \n",
       "46       True          False      True      4  \n",
       "47       True          False      True      4  \n",
       "48       True           True     False      4  \n",
       "49       True           True     False      4  \n",
       "50       True           True     False      4  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "feature_selection_df = pd.DataFrame({\n",
    "    'feature': X.columns.tolist(),\n",
    "    'Pearson': cor_support,\n",
    "    'Chi-2': chi_support,\n",
    "    'RFE': rfe_support,\n",
    "    'Logistics': embeded_lr_support,\n",
    "    'Random Forest': embeded_rf_support,\n",
    "    'LightGBM': embeded_lgb_support\n",
    "})\n",
    "\n",
    "feature_selection_df['total'] = np.sum(feature_selection_df, axis=1)\n",
    "\n",
    "feature_selection_df = feature_selection_df.sort_values(['total', 'feature'] , ascending=False)\n",
    "feature_selection_df.index = range(1, len(feature_selection_df)+1)\n",
    "feature_selection_df[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_selection_df[feature_selection_df['total'] > 5]['feature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['viral_outlier_after_iteration_5',\n",
       " 'viral_outlier_after_iteration_4',\n",
       " 'new_purchase_weekofyear_nunique']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(feature_selection_df[feature_selection_df['total'] > 5]['feature'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# all features\n",
    "features = [c for c in df_train.columns if c not in columns2drop]\n",
    "\n",
    "# features used for training the outlier detector\n",
    "#features = ['viral_outlier_after_iteration_5', 'viral_outlier_after_iteration_4']\n",
    "\n",
    "df_train_clean = df_train.dropna(how='any', axis=0, subset=features)[features]\n",
    "y = df_train_clean.outlier\n",
    "\n",
    "df_train_clean.drop(['outlier'], axis=1, inplace=True)\n",
    "X = normalize(df_train_clean)\n",
    "\n",
    "features_test = features\n",
    "features_test.remove('outlier')\n",
    "X_test = df_test.dropna(how='any', axis=0, subset=features_test)[features_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(verbose=1)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_outlier_pred = clf.predict(X_test)\n",
    "randomforest_outlier_pred_proba = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_outlier_pred.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_outlier_pred_proba.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_outlier_card_ids = []\n",
    "for i in range(len(randomforest_outlier_pred)):\n",
    "    if randomforest_outlier_pred[i] == 1:\n",
    "        print('{:,}. card_id: {}'.format(i, df_test_clean['card_id'].iloc[i]))\n",
    "        rf_outlier_card_ids.append(df_test_clean['card_id'].iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_outlier_card_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(verbose=1)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_outlier_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_outlier_pred.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_outlier_card_ids = []\n",
    "for i in range(len(logistic_regression_outlier_pred)):\n",
    "    if logistic_regression_outlier_pred[i] == 1:\n",
    "        print('{:,}. card_id: {}'.format(i, df_test_clean['card_id'].iloc[i]))\n",
    "        lr_outlier_card_ids.append(df_test_clean['card_id'].iloc[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "clf = AdaBoostClassifier()\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_outlier_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_outlier_pred.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_outlier_card_ids = []\n",
    "for i in range(len(adaboost_outlier_pred)):\n",
    "    if adaboost_outlier_pred[i] == 1:\n",
    "        print('{:,}. card_id: {}'.format(i, df_test_clean['card_id'].iloc[i]))\n",
    "        adaboost_outlier_card_ids.append(df_test_clean['card_id'].iloc[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "clf = GradientBoostingRegressor({\n",
    "    'n_estimators': 500,\n",
    "    'max_depth': 4,\n",
    "    'min_samples_split': 2,\n",
    "    'learning_rate': 0.01,\n",
    "    'loss': 'ls'\n",
    "})\n",
    "\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_boosting_outlier_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(lst1, lst2): \n",
    "    return list(set(lst1) & set(lst2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Size of the output of the logistic regression: {}\\nSize of the output of the random forest: {}\\nSize of the output of the random forest: {}'.format(len(lr_outlier_card_ids), len(rf_outlier_card_ids), len(adaboost_outlier_card_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection(lr_outlier_card_ids, rf_outlier_card_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection(lr_outlier_card_ids, adaboost_outlier_card_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection(rf_outlier_card_ids, adaboost_outlier_card_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = lgb.Booster(model_file='models/lightgbm_all.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drops = ['card_id', 'first_active_month', 'target', 'outlier']\n",
    "use_cols = [c for c in df_train.columns if c not in drops]\n",
    "features = list(df_train[use_cols].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(df_test[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = pd.DataFrame({\n",
    "    \"card_id\": df_test[\"card_id\"].values\n",
    "})\n",
    "df_sub[\"target\"] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating the intersection of RF & AdaBoost\n",
    "df_sub.loc[df_sub['card_id'] == 'C_ID_aae50409e7', 'target'] = -33.218750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(lr_outlier_card_ids)):\n",
    "    print('The value of {} is {}'.format(lr_outlier_card_ids[i], df_sub.loc[df_sub['card_id'] == lr_outlier_card_ids[i], 'target'].values[0]))\n",
    "    df_sub.loc[df_sub['card_id'] == lr_outlier_card_ids[i], 'target'] = -33.218750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_sub[df_sub['target'] < -30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.to_csv(\"output/lgbm_rf_and_adaboost_outliers.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Random Forest (LB score: 5.994)\n",
    "* Logistic Regression (LB score: 5.990)\n",
    "* Random Forest & AdaBoost (LB score: 5.986)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "261.969px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
