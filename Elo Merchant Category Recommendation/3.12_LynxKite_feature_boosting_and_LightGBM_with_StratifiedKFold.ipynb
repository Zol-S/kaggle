{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elo Merchant Category Recommendation - LynxKite feature boosting and LightGBM with StratifiedKFold\n",
    "End date: _2019. february 19._<br/>\n",
    "\n",
    "This tutorial notebook is part of a series for [Elo Mechant Category Recommendation](https://www.kaggle.com/c/elo-merchant-category-recommendation) contest organized by Elo, one of the largest payment brands in Brazil. It has built partnerships with merchants in order to offer promotions or discounts to cardholders. The objective of the competition is to identify and serve the most relevant opportunities to individuals, by uncovering signals in customer loyalty. LynxKite does not yet support some of the data preprocessing, thus they need to be done in Python. The input files are available from the [download](https://www.kaggle.com/c/elo-merchant-category-recommendation/data) section of the contest:\n",
    "\n",
    "- **train.csv**,  **test.csv**: list of `card_ids` that can be used for training and testing\n",
    "- **historical_transactions.csv**: contains up to 3 months' worth of transactions for every card at any of the provided `merchant_ids`\n",
    "- **new_merchant_transactions.csv**: contains the transactions at new merchants (`merchant_ids` that this particular `card_id` \n",
    "has not yet visited) over a period of two months\n",
    "- **merchants.csv**: contains aggregate information for each `merchant_id` represented in the data set\n",
    "\n",
    "Inspired by [Feature engineering](https://github.com/zzsza/Play-Kaggle/blob/master/Elo-Merchant-Category-Recommendation/notebooks/03.Feature-Engineering.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import random\n",
    "import warnings\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error, confusion_matrix, accuracy_score\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "random.seed(402)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Starting memory usage: {:5.2f} MB'.format(start_mem))\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min >= np.iinfo(np.int8).min and c_max <= np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min >= np.iinfo(np.int16).min and c_max <= np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min >= np.iinfo(np.int32).min and c_max <= np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min >= np.iinfo(np.int64).min and c_max <= np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min >= np.finfo(np.float16).min and c_max <= np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min >= np.finfo(np.float32).min and c_max <= np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Reduced memory usage: {:5.2f} MB ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "Inspired by [Feature Engineering](https://github.com/zzsza/Play-Kaggle/blob/master/Elo-Merchant-Category-Recommendation/notebooks/04.Feature-Engineering_2nd.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train & test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting memory usage:  9.24 MB\n",
      "Reduced memory usage:  4.04 MB (56.2% reduction)\n",
      "201,917 observations and 5 features in train set.\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"input/train.csv\", parse_dates=[\"first_active_month\"], index_col=\"card_id\")\n",
    "df_train = reduce_mem_usage(df_train)\n",
    "print(\"{:,} observations and {} features in train set.\".format(df_train.shape[0], df_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting memory usage:  4.72 MB\n",
      "Reduced memory usage:  2.24 MB (52.5% reduction)\n",
      "123,623 observations and 4 features in test set.\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"input/test.csv\", parse_dates=[\"first_active_month\"], index_col=\"card_id\")\n",
    "df_test = reduce_mem_usage(df_test)\n",
    "print(\"{:,} observations and {} features in test set.\".format(df_test.shape[0], df_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['first_active_month'] = pd.to_datetime(df_train['first_active_month'])\n",
    "df_train['elapsed_days'] = (datetime.date(2018, 2, 1) - df_train['first_active_month'].dt.date).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['first_active_month'] = pd.to_datetime(df_test['first_active_month'])\n",
    "df_test['elapsed_days'] = (datetime.date(2018, 2, 1) - df_test['first_active_month'].dt.date).dt.days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting memory usage: 3109.54 MB\n",
      "Reduced memory usage: 1749.11 MB (43.7% reduction)\n",
      "Number of historical transactions: 29,112,361\n",
      "CPU times: user 1min 20s, sys: 43.7 s, total: 2min 3s\n",
      "Wall time: 2min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_hist_trans = pd.read_csv('input/historical_transactions.csv', parse_dates=['purchase_date'])\n",
    "df_hist_trans = reduce_mem_usage(df_hist_trans)\n",
    "print('Number of historical transactions: {:,}'.format(len(df_hist_trans)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting memory usage: 209.67 MB\n",
      "Reduced memory usage: 114.20 MB (45.5% reduction)\n",
      "Number of new transactions: 1,963,031\n",
      "CPU times: user 5.64 s, sys: 672 ms, total: 6.31 s\n",
      "Wall time: 7.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_new_trans = pd.read_csv('input/new_merchant_transactions.csv', parse_dates=['purchase_date'])\n",
    "df_new_trans = reduce_mem_usage(df_new_trans)\n",
    "print('Number of new transactions: {:,}'.format(len(df_new_trans)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "authorized_flag              0\n",
       "card_id                      0\n",
       "city_id                      0\n",
       "category_1                   0\n",
       "installments                 0\n",
       "category_3               55922\n",
       "merchant_category_id         0\n",
       "merchant_id              26216\n",
       "month_lag                    0\n",
       "purchase_amount              0\n",
       "purchase_date                0\n",
       "category_2              111745\n",
       "state_id                     0\n",
       "subsector_id                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_trans.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing data handling (why these values?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [df_hist_trans, df_new_trans]:\n",
    "    df['category_2'].fillna(1.0, inplace=True)\n",
    "    df['category_3'].fillna('A', inplace=True)\n",
    "    df['merchant_id'].fillna('M_ID_00a6ca8a8a', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Date handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_date_features(df, source_column, preposition):\n",
    "    df[preposition + '_year'] = df[source_column].dt.year\n",
    "    df[preposition + '_month'] = df[source_column].dt.month\n",
    "    df[preposition + '_day'] = df[source_column].dt.day\n",
    "    df[preposition + '_hour'] = df[source_column].dt.hour\n",
    "    df[preposition + '_weekofyear'] = df[source_column].dt.weekofyear\n",
    "    df[preposition + '_dayofweek'] = df[source_column].dt.dayofweek\n",
    "    df[preposition + '_weekend'] = (df[source_column].dt.weekday >=5).astype(int)\n",
    "    df[preposition + '_quarter'] = df[source_column].dt.quarter\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist_trans['authorized_flag'] = df_hist_trans['authorized_flag'].map({'Y': 1, 'N': 0})\n",
    "df_hist_trans['category_1'] = df_hist_trans['category_1'].map({'N': 0, 'Y': 1})\n",
    "\n",
    "df_hist_trans['purchase_date'] = pd.to_datetime(df_hist_trans['purchase_date'])\n",
    "df_hist_trans = create_date_features(df_hist_trans, 'purchase_date', 'purchase')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_trans['authorized_flag'] = df_new_trans['authorized_flag'].map({'Y': 1, 'N': 0})\n",
    "df_new_trans['category_1'] = df_new_trans['category_1'].map({'N': 0, 'Y': 1})\n",
    "\n",
    "df_new_trans['purchase_date'] = pd.to_datetime(df_new_trans['purchase_date'])\n",
    "df_new_trans = create_date_features(df_new_trans, 'purchase_date', 'purchase')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist_trans['month_diff'] = ((datetime.date(2018, 12, 1) - df_hist_trans['purchase_date'].dt.date).dt.days)//30\n",
    "df_hist_trans['month_diff'] += df_hist_trans['month_lag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_trans['month_diff'] = ((datetime.date(2018, 12, 1) - df_new_trans['purchase_date'].dt.date).dt.days)//30\n",
    "df_new_trans['month_diff'] += df_new_trans['month_lag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting memory usage: 3748.10 MB\n",
      "Reduced memory usage: 1638.06 MB (56.3% reduction)\n"
     ]
    }
   ],
   "source": [
    "df_hist_trans = reduce_mem_usage(df_hist_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting memory usage: 248.99 MB\n",
      "Reduced memory usage: 106.71 MB (57.1% reduction)\n"
     ]
    }
   ],
   "source": [
    "df_new_trans = reduce_mem_usage(df_new_trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_transactions(df, prefix):\n",
    "    agg_funcs = {\n",
    "        'authorized_flag': ['sum', 'mean'],\n",
    "\n",
    "        'card_id': ['size'],\n",
    "        'category_1': ['sum', 'mean'],\n",
    "        \n",
    "        'installments': ['sum', 'max', 'min', 'mean', 'var'],\n",
    "\n",
    "        'merchant_category_id': ['nunique'],\n",
    "        'merchant_id': ['nunique'],\n",
    "        'month_diff': ['mean'],\n",
    "        'month_lag': ['max','min','mean','var'],\n",
    "\n",
    "        'purchase_amount': ['sum', 'max', 'min', 'mean', 'var'],\n",
    "        'purchase_date': ['max', 'min'],\n",
    "        'purchase_dayofweek': ['nunique'],\n",
    "        'purchase_hour': ['nunique'],\n",
    "        'purchase_month': ['nunique'],\n",
    "        'purchase_year': ['nunique'],\n",
    "        'purchase_weekend': ['sum', 'mean'],\n",
    "        'purchase_weekofyear': ['nunique'],\n",
    "\n",
    "        'subsector_id': ['nunique']\n",
    "    }\n",
    "\n",
    "    df['category_2_mean'] = df.groupby(['category_2'])['purchase_amount'].transform('mean')\n",
    "    df['category_3_mean'] = df.groupby(['category_3'])['purchase_amount'].transform('mean')\n",
    "\n",
    "    df_agg = df.groupby('card_id').agg(agg_funcs)\n",
    "    df_agg.columns = [prefix + '_' + '_'.join(col).strip() for col in df_agg.columns.values]\n",
    "    df_agg.reset_index(drop=False, inplace=True)\n",
    "    df_agg[prefix + '_purchase_date_diff'] = (df_agg[prefix + '_purchase_date_max'] - df_agg[prefix + '_purchase_date_min']).dt.days\n",
    "    df_agg[prefix + '_purchase_date_average'] = df_agg[prefix + '_purchase_date_diff']/df_agg[prefix + '_card_id_size']\n",
    "    df_agg[prefix + '_purchase_date_uptonow'] = (datetime.datetime.today() - df_agg[prefix + '_purchase_date_max']).dt.days\n",
    "\n",
    "    df = (df_agg.groupby('card_id').size().reset_index(name='{}_transactions_count'.format(prefix)))\n",
    "    df_agg = pd.merge(df, df_agg, on='card_id', how='left')\n",
    "    return df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist_agg = aggregate_transactions(df_hist_trans, 'hist')\n",
    "df_new_agg = aggregate_transactions(df_new_trans, 'new')\n",
    "\n",
    "df_train = df_train.merge(df_hist_agg, on='card_id', how='left')\n",
    "df_train = df_train.merge(df_new_agg, on='card_id', how='left')\n",
    "\n",
    "df_test = df_test.merge(df_hist_agg, on='card_id', how='left')\n",
    "df_test = df_test.merge(df_new_agg, on='card_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>hist_transactions_count</th>\n",
       "      <th>hist_authorized_flag_sum</th>\n",
       "      <th>hist_authorized_flag_mean</th>\n",
       "      <th>hist_card_id_size</th>\n",
       "      <th>hist_category_1_sum</th>\n",
       "      <th>hist_category_1_mean</th>\n",
       "      <th>hist_installments_sum</th>\n",
       "      <th>hist_installments_max</th>\n",
       "      <th>hist_installments_min</th>\n",
       "      <th>...</th>\n",
       "      <th>hist_purchase_hour_nunique</th>\n",
       "      <th>hist_purchase_month_nunique</th>\n",
       "      <th>hist_purchase_year_nunique</th>\n",
       "      <th>hist_purchase_weekend_sum</th>\n",
       "      <th>hist_purchase_weekend_mean</th>\n",
       "      <th>hist_purchase_weekofyear_nunique</th>\n",
       "      <th>hist_subsector_id_nunique</th>\n",
       "      <th>hist_purchase_date_diff</th>\n",
       "      <th>hist_purchase_date_average</th>\n",
       "      <th>hist_purchase_date_uptonow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_00007093c1</td>\n",
       "      <td>1</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.765101</td>\n",
       "      <td>149</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.187919</td>\n",
       "      <td>192</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.167785</td>\n",
       "      <td>39</td>\n",
       "      <td>13</td>\n",
       "      <td>377</td>\n",
       "      <td>2.530201</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_0001238066</td>\n",
       "      <td>1</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>123</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.016260</td>\n",
       "      <td>198</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.422764</td>\n",
       "      <td>23</td>\n",
       "      <td>17</td>\n",
       "      <td>151</td>\n",
       "      <td>1.227642</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_0001506ef0</td>\n",
       "      <td>1</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>398</td>\n",
       "      <td>6.030303</td>\n",
       "      <td>370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_id  hist_transactions_count  hist_authorized_flag_sum  \\\n",
       "0  C_ID_00007093c1                        1                     114.0   \n",
       "1  C_ID_0001238066                        1                     120.0   \n",
       "2  C_ID_0001506ef0                        1                      62.0   \n",
       "\n",
       "   hist_authorized_flag_mean  hist_card_id_size  hist_category_1_sum  \\\n",
       "0                   0.765101                149                 28.0   \n",
       "1                   0.975610                123                  2.0   \n",
       "2                   0.939394                 66                  0.0   \n",
       "\n",
       "   hist_category_1_mean  hist_installments_sum  hist_installments_max  \\\n",
       "0              0.187919                    192                      6   \n",
       "1              0.016260                    198                     10   \n",
       "2              0.000000                      1                      1   \n",
       "\n",
       "   hist_installments_min             ...              \\\n",
       "0                      1             ...               \n",
       "1                     -1             ...               \n",
       "2                      0             ...               \n",
       "\n",
       "   hist_purchase_hour_nunique  hist_purchase_month_nunique  \\\n",
       "0                          18                           12   \n",
       "1                          20                            6   \n",
       "2                          15                           11   \n",
       "\n",
       "   hist_purchase_year_nunique  hist_purchase_weekend_sum  \\\n",
       "0                           2                       25.0   \n",
       "1                           2                       52.0   \n",
       "2                           2                       32.0   \n",
       "\n",
       "   hist_purchase_weekend_mean  hist_purchase_weekofyear_nunique  \\\n",
       "0                    0.167785                                39   \n",
       "1                    0.422764                                23   \n",
       "2                    0.484848                                24   \n",
       "\n",
       "   hist_subsector_id_nunique  hist_purchase_date_diff  \\\n",
       "0                         13                      377   \n",
       "1                         17                      151   \n",
       "2                         12                      398   \n",
       "\n",
       "   hist_purchase_date_average  hist_purchase_date_uptonow  \n",
       "0                    2.530201                         360  \n",
       "1                    1.227642                         360  \n",
       "2                    6.030303                         370  \n",
       "\n",
       "[3 rows x 37 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hist_agg[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df_hist_trans, df_new_trans, df_hist_agg, df_new_agg\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['hist_first_buy'] = (df_train['hist_purchase_date_min'] - df_train['first_active_month']).dt.days\n",
    "df_train['new_first_buy'] = (df_train['new_purchase_date_min'] - df_train['first_active_month']).dt.days\n",
    "\n",
    "df_test['hist_first_buy'] = (df_test['hist_purchase_date_min'] - df_test['first_active_month']).dt.days\n",
    "df_test['new_first_buy'] = (df_test['new_purchase_date_min'] - df_test['first_active_month']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in ['hist_purchase_date_max', 'hist_purchase_date_min', 'new_purchase_date_max', 'new_purchase_date_min']:\n",
    "    df_train[f] = df_train[f].astype(np.int64) * 1e-9\n",
    "    df_test[f] = df_test[f].astype(np.int64) * 1e-9\n",
    "\n",
    "df_train['card_id_total'] = df_train['hist_card_id_size'] + df_train['new_card_id_size']\n",
    "df_test['card_id_total'] = df_test['hist_card_id_size'] + df_test['new_card_id_size']\n",
    "\n",
    "df_train['purchase_amount_total'] = df_train['hist_purchase_amount_sum'] + df_train['new_purchase_amount_sum']\n",
    "df_test['purchase_amount_total'] = df_test['hist_purchase_amount_sum'] + df_test['new_purchase_amount_sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    199710\n",
       "1      2207\n",
       "Name: outliers, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['outliers'] = 0\n",
    "df_train.loc[df_train['target'] < -30, 'outliers'] = 1\n",
    "df_train['outliers'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in ['feature_1', 'feature_2', 'feature_3']:\n",
    "    order_label = df_train.groupby([f])['outliers'].mean()\n",
    "    df_train[f] = df_train[f].map(order_label)\n",
    "    df_test[f] = df_test[f].map(order_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading possible outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting memory usage:  3.08 MB\n",
      "Reduced memory usage:  1.73 MB (43.8% reduction)\n",
      "201,917 observations and 1 features in train set.\n"
     ]
    }
   ],
   "source": [
    "df_train_po = pd.read_csv(\"preprocessed/beas_possible_outliers_train_gt0.9.csv\", index_col=\"card_id\")\n",
    "df_train_po = reduce_mem_usage(df_train_po)\n",
    "print(\"{:,} observations and {} features in train set.\".format(df_train_po.shape[0], df_train_po.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_po = pd.read_csv(\"preprocessed/beas_possible_outliers_gt0.9.csv\", index_col=\"card_id\")\n",
    "df_test_po = reduce_mem_usage(df_test_po)\n",
    "print(\"{:,} observations and {} features in train set.\".format(df_test_po.shape[0], df_test_po.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "possible_out    31039\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train_po[df_train_po['possible_out'] == 1]),\n",
    "len(df_test_po[df_test_po['possible_out'] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.merge(df_train_po, on='card_id', how='left')\n",
    "df_test = df_test.merge(df_test_po, on='card_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>first_active_month</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>target</th>\n",
       "      <th>elapsed_days</th>\n",
       "      <th>hist_transactions_count</th>\n",
       "      <th>hist_authorized_flag_sum</th>\n",
       "      <th>hist_authorized_flag_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>new_subsector_id_nunique</th>\n",
       "      <th>new_purchase_date_diff</th>\n",
       "      <th>new_purchase_date_average</th>\n",
       "      <th>new_purchase_date_uptonow</th>\n",
       "      <th>hist_first_buy</th>\n",
       "      <th>new_first_buy</th>\n",
       "      <th>card_id_total</th>\n",
       "      <th>purchase_amount_total</th>\n",
       "      <th>outliers</th>\n",
       "      <th>possible_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_92a2005557</td>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>0.013145</td>\n",
       "      <td>0.008752</td>\n",
       "      <td>0.011428</td>\n",
       "      <td>-0.820312</td>\n",
       "      <td>245</td>\n",
       "      <td>1</td>\n",
       "      <td>247.0</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.347826</td>\n",
       "      <td>299.0</td>\n",
       "      <td>26</td>\n",
       "      <td>277.0</td>\n",
       "      <td>283.0</td>\n",
       "      <td>-179.210922</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_3d0044924f</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>0.010712</td>\n",
       "      <td>0.011385</td>\n",
       "      <td>0.010283</td>\n",
       "      <td>0.392822</td>\n",
       "      <td>396</td>\n",
       "      <td>1</td>\n",
       "      <td>339.0</td>\n",
       "      <td>0.968571</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>329.0</td>\n",
       "      <td>5</td>\n",
       "      <td>396.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>-214.361801</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_d639edf6cd</td>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>0.010610</td>\n",
       "      <td>0.008752</td>\n",
       "      <td>0.010283</td>\n",
       "      <td>0.687988</td>\n",
       "      <td>549</td>\n",
       "      <td>1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>299.0</td>\n",
       "      <td>163</td>\n",
       "      <td>635.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>-29.867586</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_id first_active_month  feature_1  feature_2  feature_3  \\\n",
       "0  C_ID_92a2005557         2017-06-01   0.013145   0.008752   0.011428   \n",
       "1  C_ID_3d0044924f         2017-01-01   0.010712   0.011385   0.010283   \n",
       "2  C_ID_d639edf6cd         2016-08-01   0.010610   0.008752   0.010283   \n",
       "\n",
       "     target  elapsed_days  hist_transactions_count  hist_authorized_flag_sum  \\\n",
       "0 -0.820312           245                        1                     247.0   \n",
       "1  0.392822           396                        1                     339.0   \n",
       "2  0.687988           549                        1                      41.0   \n",
       "\n",
       "   hist_authorized_flag_mean      ...       new_subsector_id_nunique  \\\n",
       "0                   0.950000      ...                           10.0   \n",
       "1                   0.968571      ...                            4.0   \n",
       "2                   0.953488      ...                            1.0   \n",
       "\n",
       "   new_purchase_date_diff  new_purchase_date_average  \\\n",
       "0                    54.0                   2.347826   \n",
       "1                    56.0                   9.333333   \n",
       "2                     0.0                   0.000000   \n",
       "\n",
       "   new_purchase_date_uptonow  hist_first_buy  new_first_buy  card_id_total  \\\n",
       "0                      299.0              26          277.0          283.0   \n",
       "1                      329.0               5          396.0          356.0   \n",
       "2                      299.0             163          635.0           44.0   \n",
       "\n",
       "   purchase_amount_total  outliers  possible_out  \n",
       "0            -179.210922         0             0  \n",
       "1            -214.361801         0             0  \n",
       "2             -29.867586         0             0  \n",
       "\n",
       "[3 rows x 85 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading features from LynxKite"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_lk_mc = pd.read_csv(\"LynxKite_export/LynxKite-modular_clusters_id_first.csv\", index_col=\"card_id\")\n",
    "df_lk_mc = reduce_mem_usage(df_lk_mc)\n",
    "print(\"{:,} observations and {} features in train set.\".format(df_lk_mc.shape[0], df_lk_mc.shape[1]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df_lk_mc['modular_clusters_id_first'])\n",
    "df_lk_mc['modular_clusters_id_first'] = le.transform(df_lk_mc['modular_clusters_id_first'])\n",
    "\n",
    "le.fit(df_lk_mc['modular_clusters_size_first'])\n",
    "df_lk_mc['modular_clusters_size_first'] = le.transform(df_lk_mc['modular_clusters_size_first'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_lk_mc[:3]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_lk_tt = pd.read_csv(\"LynxKite_export/LynxKite-target_top-target_wavg_purchase_amount-wavg_purchase_date.csv\")\n",
    "df_lk_tt = reduce_mem_usage(df_lk_tt)\n",
    "print(\"{:,} observations and {} features in train set.\".format(df_lk_tt.shape[0], df_lk_tt.shape[1]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "df_lk_tt[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_train = df_train.merge(df_lk_mc, on='card_id', how='left')\n",
    "df_test = df_test.merge(df_lk_mc, on='card_id', how='left')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_train = df_train.merge(df_lk_tt, on='card_id', how='left')\n",
    "df_test = df_test.merge(df_lk_tt, on='card_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "[LightGBM parameter tuning](https://testlightgbm.readthedocs.io/en/latest/Parameters-tuning.html)<br/>\n",
    "[What is LightGBM, How to implement it? How to fine tune the parameters?](https://medium.com/@pushkarmandot/https-medium-com-pushkarmandot-what-is-lightgbm-how-to-implement-it-how-to-fine-tune-the-parameters-60347819b7fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_columns = [c for c in df_train.columns if c not in ['card_id', 'first_active_month', 'target', 'outliers']]\n",
    "target = df_train['target']\n",
    "del df_train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1.\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's rmse: 3.65405\tvalid_1's rmse: 3.77197\n",
      "[200]\ttraining's rmse: 3.57797\tvalid_1's rmse: 3.73959\n",
      "[300]\ttraining's rmse: 3.53131\tvalid_1's rmse: 3.72661\n",
      "[400]\ttraining's rmse: 3.49661\tvalid_1's rmse: 3.71887\n",
      "[500]\ttraining's rmse: 3.4671\tvalid_1's rmse: 3.71411\n",
      "[600]\ttraining's rmse: 3.4428\tvalid_1's rmse: 3.71002\n",
      "[700]\ttraining's rmse: 3.42102\tvalid_1's rmse: 3.7068\n",
      "[800]\ttraining's rmse: 3.40224\tvalid_1's rmse: 3.7049\n",
      "[900]\ttraining's rmse: 3.3833\tvalid_1's rmse: 3.70283\n",
      "[1000]\ttraining's rmse: 3.36605\tvalid_1's rmse: 3.70192\n",
      "[1100]\ttraining's rmse: 3.35061\tvalid_1's rmse: 3.70156\n",
      "[1200]\ttraining's rmse: 3.33437\tvalid_1's rmse: 3.70053\n",
      "[1300]\ttraining's rmse: 3.31927\tvalid_1's rmse: 3.69974\n",
      "[1400]\ttraining's rmse: 3.30494\tvalid_1's rmse: 3.69969\n",
      "[1500]\ttraining's rmse: 3.29132\tvalid_1's rmse: 3.69901\n",
      "[1600]\ttraining's rmse: 3.27671\tvalid_1's rmse: 3.69868\n",
      "[1700]\ttraining's rmse: 3.26289\tvalid_1's rmse: 3.69864\n",
      "[1800]\ttraining's rmse: 3.24982\tvalid_1's rmse: 3.69897\n",
      "Early stopping, best iteration is:\n",
      "[1717]\ttraining's rmse: 3.26057\tvalid_1's rmse: 3.69847\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['possible_out'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2680\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2681\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2682\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2683\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2684\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2724\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2725\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2726\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2727\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[1;32m   1325\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m                     raise KeyError('{mask} not in index'\n\u001b[0;32m-> 1327\u001b[0;31m                                    .format(mask=objarr[mask]))\n\u001b[0m\u001b[1;32m   1328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['possible_out'] not in index\""
     ]
    }
   ],
   "source": [
    "%%time\n",
    "param = {\n",
    "    \"bagging_freq\": 1,\n",
    "    \"bagging_fraction\": 0.9,\n",
    "    \"bagging_seed\": 11,\n",
    "    \"boosting\": \"gbdt\",\n",
    "\n",
    "    \"feature_fraction\": 0.9,\n",
    "    \"feature_fraction_seed\": 1,\n",
    "\n",
    "    \"lambda_l1\": 0.1,\n",
    "    #\"lambda_l2\": 0.001,\n",
    "    \"learning_rate\": 0.01,\n",
    "\n",
    "    #\"max_bin\": 5,\n",
    "    'max_depth': -1,\n",
    "    \"metric\": \"rmse\",\n",
    "    \"min_data_in_leaf\": 30,\n",
    "    #\"min_gain_to_split\": 0.1,\n",
    "    #\"min_sum_hessian_in_leaf\": 1e-3,\n",
    "    \"min_child_samples\": 20,\n",
    "    #\"num_iterations\": 100,\n",
    "    #\"num_boost_round\": 100,\n",
    "    \"num_leaves\": 31,\n",
    "    \"nthread\": -1,\n",
    "\n",
    "    \"objective\": \"regression\",\n",
    "\n",
    "    \"random_state\": 402,\n",
    "    \"verbosity\": -1\n",
    "}\n",
    "\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=402)\n",
    "oof = np.zeros(len(df_train))\n",
    "predictions = np.zeros(len(df_test))\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(df_train, df_train['possible_out'].values)):\n",
    "    print(\"\\nFold {}.\".format(fold_+1))\n",
    "    trn_data = lgb.Dataset(df_train.iloc[trn_idx][df_train_columns], label=target.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(df_train.iloc[val_idx][df_train_columns], label=target.iloc[val_idx])\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=100, early_stopping_rounds=100)\n",
    "    oof[val_idx] = clf.predict(df_train.iloc[val_idx][df_train_columns], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = df_train_columns\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    \n",
    "    predictions += clf.predict(df_test[df_train_columns], num_iteration=clf.best_iteration) / folds.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score: 3.870509\n"
     ]
    }
   ],
   "source": [
    "cv_score = np.sqrt(mean_squared_error(oof, target))\n",
    "print(\"CV score: {:.6f}\".format(cv_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(target, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = (feature_importance_df[[\"feature\", \"importance\"]]\n",
    "        .groupby(\"feature\")\n",
    "        .mean()\n",
    "        .sort_values(by=\"importance\", ascending=False)[:1000].index)\n",
    "\n",
    "best_features = feature_importance_df.loc[feature_importance_df.feature.isin(cols)]\n",
    "\n",
    "plt.figure(figsize=(14, 25))\n",
    "sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "plt.title('LightGBM Features (avg over folds)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('lgbm_importances.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features[best_features['importance'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.DataFrame({\n",
    "    \"card_id\": df_test[\"card_id\"].values\n",
    "})\n",
    "\n",
    "sub_df[\"target\"] = predictions\n",
    "sub_df.to_csv(\"output/regression_with_lk_{:.6f}.csv\".format(cv_score), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Just Train Data - LGB & XGB & CatBoost w/ Blending](https://www.kaggle.com/silverstone1903/just-train-data-lgb-xgb-catboost-w-blending/data)<br/>\n",
    "[MultiModel + RIDGE + STACKING](https://www.kaggle.com/ashishpatel26/rmse-3-66-multimodel-ridge-stacking)\n",
    "https://www.kaggle.com/c/elo-merchant-category-recommendation/discussion/75935"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "169.969px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
