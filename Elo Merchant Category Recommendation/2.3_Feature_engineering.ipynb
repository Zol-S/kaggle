{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elo Merchant Category Recommendation - Feature engineering\n",
    "End date: _2019. february 19._<br/>\n",
    "\n",
    "This tutorial notebook is part of a series for [Elo Mechant Category Recommendation](https://www.kaggle.com/c/elo-merchant-category-recommendation) contest organized by Elo, one of the largest payment brands in Brazil. It has built partnerships with merchants in order to offer promotions or discounts to cardholders. The objective of the competition is to identify and serve the most relevant opportunities to individuals, by uncovering signals in customer loyalty. LynxKite does not yet support some of the data preprocessing, thus they need to be done in Python. The input files are available from the [download](https://www.kaggle.com/c/elo-merchant-category-recommendation/data) section of the contest:\n",
    "\n",
    "- **train.csv**,  **test.csv**: list of `card_ids` that can be used for training and testing\n",
    "- **historical_transactions.csv**: contains up to 3 months' worth of transactions for every card at any of the provided `merchant_ids`\n",
    "- **new_merchant_transactions.csv**: contains the transactions at new merchants (`merchant_ids` that this particular `card_id` \n",
    "has not yet visited) over a period of two months\n",
    "- **merchants.csv**: contains aggregate information for each `merchant_id` represented in the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import time\n",
    "import warnings\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "from lightgbm import LGBMClassifier\n",
    "import matplotlib.gridspec as gridspec\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.simplefilter('ignore', UserWarning)\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Starting memory usage: {:5.2f} MB'.format(start_mem))\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min >= np.iinfo(np.int8).min and c_max <= np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min >= np.iinfo(np.int16).min and c_max <= np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min >= np.iinfo(np.int32).min and c_max <= np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min >= np.iinfo(np.int64).min and c_max <= np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min >= np.finfo(np.float16).min and c_max <= np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min >= np.finfo(np.float32).min and c_max <= np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Reduced memory usage: {:5.2f} MB ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data preparation\n",
    "### Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting memory usage: 354.01 MB\n",
      "Reduced memory usage: 83.25 MB (76.5% reduction)\n",
      "Starting memory usage: 397.39 MB\n",
      "Reduced memory usage: 110.83 MB (72.1% reduction)\n"
     ]
    }
   ],
   "source": [
    "df_new_trans = pd.read_csv(\"input/trans_merch_new_agg.csv\", index_col='card_id')\n",
    "df_new_trans = reduce_mem_usage(df_new_trans)\n",
    "\n",
    "df_hist_trans = pd.read_csv(\"input/trans_merch_hist_agg.csv\", index_col='card_id')\n",
    "df_hist_trans = reduce_mem_usage(df_hist_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist_trans.drop(['Unnamed: 0'], inplace=True, axis=1)\n",
    "df_new_trans.drop(['Unnamed: 0'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_hist_trans = pd.read_csv(\"input/historical_transactions.csv\", index_col='card_id')\n",
    "df_hist_trans = reduce_mem_usage(df_hist_trans)\n",
    "print('Number of historical transactions: {:,}'.format(len(df_hist_trans)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_new_trans = pd.read_csv(\"input/new_merchant_transactions.csv\", index_col='card_id')\n",
    "df_new_trans = reduce_mem_usage(df_new_trans)\n",
    "print('Number of new transactions: {:,}'.format(len(df_new_trans)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_trans[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist_trans['authorized_flag'] = df_hist_trans['authorized_flag'].map({'Y': 1, 'N': 0})\n",
    "df_hist_trans['category_1'] = df_hist_trans['category_1'].map({'Y': 1, 'N': 0})\n",
    "\n",
    "df_hist_trans['purchase_date'] = pd.to_datetime(df_hist_trans['purchase_date'])\n",
    "df_hist_trans = create_date_features(df_hist_trans, 'purchase_date', 'purchase')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_trans['authorized_flag'] = df_new_trans['authorized_flag'].map({'Y': 1, 'N': 0})\n",
    "df_new_trans['category_1'] = df_new_trans['category_1'].map({'Y': 1, 'N': 0})\n",
    "\n",
    "df_new_trans['purchase_date'] = pd.to_datetime(df_new_trans['purchase_date'])\n",
    "df_new_trans = create_date_features(df_new_trans, 'purchase_date', 'purchase')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist_trans[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_trans[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to save transactions connecting specific customer vertices, use the block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_hist_trans.to_csv('preprocessed/trans_hist.csv')\n",
    "df_new_trans.to_csv('preprocessed/trans_new.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating the number of transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist_gb_card_id = df_hist_trans.groupby(\"card_id\").size().reset_index().set_index('card_id').sort_index(axis=1).rename({0:'number_of_transactions'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist_gb_card_id[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist_gb_merchant_id = df_hist_trans.groupby(\"merchant_id\").size().reset_index().set_index('merchant_id').sort_index(axis=1).rename({0:'number_of_transactions'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist_gb_merchant_id[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting memory usage:  9.24 MB\n",
      "Reduced memory usage:  4.04 MB (56.2% reduction)\n",
      "201,917 observations and 5 features in train set.\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"input/train.csv\", parse_dates=[\"first_active_month\"], index_col=\"card_id\")\n",
    "df_train = reduce_mem_usage(df_train)\n",
    "print(\"{:,} observations and {} features in train set.\".format(df_train.shape[0], df_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting memory usage:  4.72 MB\n",
      "Reduced memory usage:  2.24 MB (52.5% reduction)\n",
      "123,623 observations and 4 features in test set.\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"input/test.csv\", parse_dates=[\"first_active_month\"], index_col=\"card_id\")\n",
    "df_test = reduce_mem_usage(df_test)\n",
    "print(\"{:,} observations and {} features in test set.\".format(df_test.shape[0], df_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_active_month</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>card_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C_ID_92a2005557</th>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.820312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_3d0044924f</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.392822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_d639edf6cd</th>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.687988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                first_active_month  feature_1  feature_2  feature_3    target\n",
       "card_id                                                                      \n",
       "C_ID_92a2005557         2017-06-01          5          2          1 -0.820312\n",
       "C_ID_3d0044924f         2017-01-01          4          1          0  0.392822\n",
       "C_ID_d639edf6cd         2016-08-01          2          2          0  0.687988"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_active_month</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>card_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C_ID_0ab67a22ab</th>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_130fd0cbdd</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_b709037bc5</th>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                first_active_month  feature_1  feature_2  feature_3\n",
       "card_id                                                            \n",
       "C_ID_0ab67a22ab         2017-04-01          3          3          1\n",
       "C_ID_130fd0cbdd         2017-01-01          2          3          0\n",
       "C_ID_b709037bc5         2017-08-01          5          1          1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"year\"] = df_train[\"first_active_month\"].dt.year\n",
    "df_train[\"month\"] = df_train[\"first_active_month\"].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"year\"] = df_test[\"first_active_month\"].dt.year\n",
    "df_test[\"month\"] = df_test[\"first_active_month\"].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.merge(df_train, df_hist_gb_card_id, left_index=True, right_index=True, how='left')\n",
    "df_test = pd.merge(df_test, df_hist_gb_card_id, left_index=True, right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('preprocessed/train_parsed.csv')\n",
    "df_test.to_csv('preprocessed/test_parsed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merchants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merch = pd.read_csv(\"input/merchants.csv\", index_col=\"merchant_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merch = df_merch.groupby(df_merch.index).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merchant_group_id</th>\n",
       "      <th>merchant_category_id</th>\n",
       "      <th>subsector_id</th>\n",
       "      <th>numerical_1</th>\n",
       "      <th>numerical_2</th>\n",
       "      <th>category_1</th>\n",
       "      <th>most_recent_sales_range</th>\n",
       "      <th>most_recent_purchases_range</th>\n",
       "      <th>avg_sales_lag3</th>\n",
       "      <th>avg_purchases_lag3</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_sales_lag6</th>\n",
       "      <th>avg_purchases_lag6</th>\n",
       "      <th>active_months_lag6</th>\n",
       "      <th>avg_sales_lag12</th>\n",
       "      <th>avg_purchases_lag12</th>\n",
       "      <th>active_months_lag12</th>\n",
       "      <th>category_4</th>\n",
       "      <th>city_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>category_2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merchant_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>M_ID_000025127f</th>\n",
       "      <td>14602</td>\n",
       "      <td>80</td>\n",
       "      <td>37</td>\n",
       "      <td>-0.057471</td>\n",
       "      <td>-0.057471</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>1.29</td>\n",
       "      <td>1.880342</td>\n",
       "      <td>...</td>\n",
       "      <td>1.26</td>\n",
       "      <td>2.228632</td>\n",
       "      <td>6</td>\n",
       "      <td>1.08</td>\n",
       "      <td>2.089744</td>\n",
       "      <td>12</td>\n",
       "      <td>Y</td>\n",
       "      <td>69</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M_ID_0000699140</th>\n",
       "      <td>19420</td>\n",
       "      <td>87</td>\n",
       "      <td>27</td>\n",
       "      <td>-0.057471</td>\n",
       "      <td>-0.057471</td>\n",
       "      <td>N</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.997832</td>\n",
       "      <td>...</td>\n",
       "      <td>1.04</td>\n",
       "      <td>1.002168</td>\n",
       "      <td>6</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1.154878</td>\n",
       "      <td>12</td>\n",
       "      <td>N</td>\n",
       "      <td>48</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M_ID_00006a5552</th>\n",
       "      <td>52848</td>\n",
       "      <td>178</td>\n",
       "      <td>29</td>\n",
       "      <td>-0.057471</td>\n",
       "      <td>-0.057471</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>1.21</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.035714</td>\n",
       "      <td>12</td>\n",
       "      <td>N</td>\n",
       "      <td>64</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 merchant_group_id  merchant_category_id  subsector_id  \\\n",
       "merchant_id                                                              \n",
       "M_ID_000025127f              14602                    80            37   \n",
       "M_ID_0000699140              19420                    87            27   \n",
       "M_ID_00006a5552              52848                   178            29   \n",
       "\n",
       "                 numerical_1  numerical_2 category_1 most_recent_sales_range  \\\n",
       "merchant_id                                                                    \n",
       "M_ID_000025127f    -0.057471    -0.057471          N                       E   \n",
       "M_ID_0000699140    -0.057471    -0.057471          N                       D   \n",
       "M_ID_00006a5552    -0.057471    -0.057471          N                       E   \n",
       "\n",
       "                most_recent_purchases_range  avg_sales_lag3  \\\n",
       "merchant_id                                                   \n",
       "M_ID_000025127f                           E            1.29   \n",
       "M_ID_0000699140                           D            0.99   \n",
       "M_ID_00006a5552                           E            1.21   \n",
       "\n",
       "                 avg_purchases_lag3     ...      avg_sales_lag6  \\\n",
       "merchant_id                             ...                       \n",
       "M_ID_000025127f            1.880342     ...                1.26   \n",
       "M_ID_0000699140            0.997832     ...                1.04   \n",
       "M_ID_00006a5552            1.000000     ...                1.18   \n",
       "\n",
       "                 avg_purchases_lag6  active_months_lag6  avg_sales_lag12  \\\n",
       "merchant_id                                                                \n",
       "M_ID_000025127f            2.228632                   6             1.08   \n",
       "M_ID_0000699140            1.002168                   6             1.24   \n",
       "M_ID_00006a5552            1.000000                   6             1.22   \n",
       "\n",
       "                 avg_purchases_lag12  active_months_lag12  category_4 city_id  \\\n",
       "merchant_id                                                                     \n",
       "M_ID_000025127f             2.089744                   12           Y      69   \n",
       "M_ID_0000699140             1.154878                   12           N      48   \n",
       "M_ID_00006a5552             1.035714                   12           N      64   \n",
       "\n",
       "                 state_id  category_2  \n",
       "merchant_id                            \n",
       "M_ID_000025127f         9         1.0  \n",
       "M_ID_0000699140         9         1.0  \n",
       "M_ID_00006a5552        15         1.0  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merch[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merch['category_1'] = df_merch['category_1'].map({'N': 0, 'Y': 1})\n",
    "df_merch['category_2'] = pd.to_numeric(df_merch['category_2'])\n",
    "df_merch['category_4'] = df_merch['category_4'].map({'N': 0, 'Y': 1})\n",
    "df_merch['most_recent_sales_range'] = df_merch['most_recent_sales_range'].map({'E': 0, 'D': 1, 'C': 2, 'B': 3, 'A': 4})\n",
    "df_merch['most_recent_purchases_range'] = df_merch['most_recent_purchases_range'].map({'E': 0, 'D': 1, 'C': 2, 'B': 3, 'A': 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merch = pd.merge(df_merch, df_hist_gb_merchant_id, left_index=True, right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merch.to_csv('preprocessed/merchants_parsed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.merge(df_train, df_hist_trans, on='card_id', how='left')\n",
    "df_test = pd.merge(df_test, df_hist_trans, on='card_id', how='left')\n",
    "\n",
    "df_train = pd.merge(df_train, df_new_trans, on='card_id', how='left')\n",
    "df_test = pd.merge(df_test, df_new_trans, on='card_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_active_month</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>target</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>hist_transactions_count</th>\n",
       "      <th>hist_authorized_flag_sum</th>\n",
       "      <th>hist_authorized_flag_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>new_purchase_dayofweek_max</th>\n",
       "      <th>new_purchase_dayofweek_min</th>\n",
       "      <th>new_purchase_dayofweek_std</th>\n",
       "      <th>new_purchase_dayofweek_mode</th>\n",
       "      <th>new_purchase_quarter_mean</th>\n",
       "      <th>new_purchase_quarter_median</th>\n",
       "      <th>new_purchase_quarter_max</th>\n",
       "      <th>new_purchase_quarter_min</th>\n",
       "      <th>new_purchase_quarter_std</th>\n",
       "      <th>new_purchase_quarter_mode</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>card_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C_ID_92a2005557</th>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.820312</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>252.0</td>\n",
       "      <td>0.951172</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.029297</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.478516</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.510742</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_3d0044924f</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.392822</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>354.0</td>\n",
       "      <td>0.969727</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.643555</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_d639edf6cd</th>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.687988</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.954590</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 323 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                first_active_month  feature_1  feature_2  feature_3    target  \\\n",
       "card_id                                                                         \n",
       "C_ID_92a2005557         2017-06-01          5          2          1 -0.820312   \n",
       "C_ID_3d0044924f         2017-01-01          4          1          0  0.392822   \n",
       "C_ID_d639edf6cd         2016-08-01          2          2          0  0.687988   \n",
       "\n",
       "                 year  month  hist_transactions_count  \\\n",
       "card_id                                                 \n",
       "C_ID_92a2005557  2017      6                        1   \n",
       "C_ID_3d0044924f  2017      1                        1   \n",
       "C_ID_d639edf6cd  2016      8                        1   \n",
       "\n",
       "                 hist_authorized_flag_sum  hist_authorized_flag_mean  \\\n",
       "card_id                                                                \n",
       "C_ID_92a2005557                     252.0                   0.951172   \n",
       "C_ID_3d0044924f                     354.0                   0.969727   \n",
       "C_ID_d639edf6cd                      42.0                   0.954590   \n",
       "\n",
       "                           ...              new_purchase_dayofweek_max  \\\n",
       "card_id                    ...                                           \n",
       "C_ID_92a2005557            ...                                     6.0   \n",
       "C_ID_3d0044924f            ...                                     4.0   \n",
       "C_ID_d639edf6cd            ...                                     5.0   \n",
       "\n",
       "                 new_purchase_dayofweek_min  new_purchase_dayofweek_std  \\\n",
       "card_id                                                                   \n",
       "C_ID_92a2005557                         0.0                    2.029297   \n",
       "C_ID_3d0044924f                         0.0                    1.643555   \n",
       "C_ID_d639edf6cd                         5.0                         NaN   \n",
       "\n",
       "                 new_purchase_dayofweek_mode  new_purchase_quarter_mean  \\\n",
       "card_id                                                                   \n",
       "C_ID_92a2005557                          4.0                   1.478516   \n",
       "C_ID_3d0044924f                          0.0                   1.000000   \n",
       "C_ID_d639edf6cd                          5.0                   2.000000   \n",
       "\n",
       "                 new_purchase_quarter_median  new_purchase_quarter_max  \\\n",
       "card_id                                                                  \n",
       "C_ID_92a2005557                          1.0                       2.0   \n",
       "C_ID_3d0044924f                          1.0                       1.0   \n",
       "C_ID_d639edf6cd                          2.0                       2.0   \n",
       "\n",
       "                 new_purchase_quarter_min  new_purchase_quarter_std  \\\n",
       "card_id                                                               \n",
       "C_ID_92a2005557                       1.0                  0.510742   \n",
       "C_ID_3d0044924f                       1.0                  0.000000   \n",
       "C_ID_d639edf6cd                       2.0                       NaN   \n",
       "\n",
       "                 new_purchase_quarter_mode  \n",
       "card_id                                     \n",
       "C_ID_92a2005557                        1.0  \n",
       "C_ID_3d0044924f                        1.0  \n",
       "C_ID_d639edf6cd                        2.0  \n",
       "\n",
       "[3 rows x 323 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_active_month</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>hist_transactions_count</th>\n",
       "      <th>hist_authorized_flag_sum</th>\n",
       "      <th>hist_authorized_flag_mean</th>\n",
       "      <th>hist_active_months_lag3_sum</th>\n",
       "      <th>...</th>\n",
       "      <th>new_purchase_dayofweek_max</th>\n",
       "      <th>new_purchase_dayofweek_min</th>\n",
       "      <th>new_purchase_dayofweek_std</th>\n",
       "      <th>new_purchase_dayofweek_mode</th>\n",
       "      <th>new_purchase_quarter_mean</th>\n",
       "      <th>new_purchase_quarter_median</th>\n",
       "      <th>new_purchase_quarter_max</th>\n",
       "      <th>new_purchase_quarter_min</th>\n",
       "      <th>new_purchase_quarter_std</th>\n",
       "      <th>new_purchase_quarter_mode</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>card_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C_ID_0ab67a22ab</th>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.662109</td>\n",
       "      <td>213.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.527344</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_130fd0cbdd</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.987305</td>\n",
       "      <td>234.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.359375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.400391</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.516602</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_ID_b709037bc5</th>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.692383</td>\n",
       "      <td>39.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.414062</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 322 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                first_active_month  feature_1  feature_2  feature_3    year  \\\n",
       "card_id                                                                       \n",
       "C_ID_0ab67a22ab         2017-04-01          3          3          1  2017.0   \n",
       "C_ID_130fd0cbdd         2017-01-01          2          3          0  2017.0   \n",
       "C_ID_b709037bc5         2017-08-01          5          1          1  2017.0   \n",
       "\n",
       "                 month  hist_transactions_count  hist_authorized_flag_sum  \\\n",
       "card_id                                                                     \n",
       "C_ID_0ab67a22ab    4.0                        1                      47.0   \n",
       "C_ID_130fd0cbdd    1.0                        1                      77.0   \n",
       "C_ID_b709037bc5    8.0                        1                       9.0   \n",
       "\n",
       "                 hist_authorized_flag_mean  hist_active_months_lag3_sum  \\\n",
       "card_id                                                                   \n",
       "C_ID_0ab67a22ab                   0.662109                        213.0   \n",
       "C_ID_130fd0cbdd                   0.987305                        234.0   \n",
       "C_ID_b709037bc5                   0.692383                         39.0   \n",
       "\n",
       "                           ...              new_purchase_dayofweek_max  \\\n",
       "card_id                    ...                                           \n",
       "C_ID_0ab67a22ab            ...                                     5.0   \n",
       "C_ID_130fd0cbdd            ...                                     6.0   \n",
       "C_ID_b709037bc5            ...                                     3.0   \n",
       "\n",
       "                 new_purchase_dayofweek_min  new_purchase_dayofweek_std  \\\n",
       "card_id                                                                   \n",
       "C_ID_0ab67a22ab                         2.0                    1.527344   \n",
       "C_ID_130fd0cbdd                         0.0                    2.359375   \n",
       "C_ID_b709037bc5                         1.0                    1.414062   \n",
       "\n",
       "                 new_purchase_dayofweek_mode  new_purchase_quarter_mean  \\\n",
       "card_id                                                                   \n",
       "C_ID_0ab67a22ab                          2.0                   1.000000   \n",
       "C_ID_130fd0cbdd                          0.0                   1.400391   \n",
       "C_ID_b709037bc5                          1.0                   1.000000   \n",
       "\n",
       "                 new_purchase_quarter_median  new_purchase_quarter_max  \\\n",
       "card_id                                                                  \n",
       "C_ID_0ab67a22ab                          1.0                       1.0   \n",
       "C_ID_130fd0cbdd                          1.0                       2.0   \n",
       "C_ID_b709037bc5                          1.0                       1.0   \n",
       "\n",
       "                 new_purchase_quarter_min  new_purchase_quarter_std  \\\n",
       "card_id                                                               \n",
       "C_ID_0ab67a22ab                       1.0                  0.000000   \n",
       "C_ID_130fd0cbdd                       1.0                  0.516602   \n",
       "C_ID_b709037bc5                       1.0                  0.000000   \n",
       "\n",
       "                 new_purchase_quarter_mode  \n",
       "card_id                                     \n",
       "C_ID_0ab67a22ab                        1.0  \n",
       "C_ID_130fd0cbdd                        1.0  \n",
       "C_ID_b709037bc5                        1.0  \n",
       "\n",
       "[3 rows x 322 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Others' feature engineerings\n",
    "[Boruta feature elimination](https://www.kaggle.com/tilii7/boruta-feature-elimination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Feature Selection with Null Importances](https://www.kaggle.com/ogrellier/feature-selection-with-null-importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(['first_active_month', 'hist_merchant_id_mode', 'new_merchant_id_mode'], axis=1, inplace=True)\n",
    "df_test.drop(['first_active_month', 'hist_merchant_id_mode', 'new_merchant_id_mode'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.dropna(axis=0, how='any', inplace=True)\n",
    "df_test.dropna(axis=0, how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://lightgbm.readthedocs.io/en/latest/Parameters.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_importances(data, shuffle, seed=None):\n",
    "    train_features = [f for f in data if f not in ['card_id', 'target']]\n",
    "    y = data['target'].copy()\n",
    "    if shuffle:\n",
    "        y = data['target'].copy().sample(frac=1.0)\n",
    "\n",
    "    dtrain = lgb.Dataset(data[train_features], y, free_raw_data=False, silent=True)\n",
    "    lgb_params = {\n",
    "        'bagging_freq': 1,\n",
    "        'boosting_type': 'gbdt', # rf\n",
    "        'colsample_bytree': 0.7,\n",
    "        'max_depth': 8,\n",
    "        'num_leaves': 127,\n",
    "        'n_jobs': 4,\n",
    "        'objective': 'binary',\n",
    "        'seed': seed,\n",
    "        'subsample': 0.623\n",
    "    }\n",
    "    \n",
    "    clf = lgb.train(params=lgb_params, train_set=dtrain, num_boost_round=200)\n",
    "    #, categorical_feature=categorical_feats\n",
    "\n",
    "    imp_df = pd.DataFrame()\n",
    "    imp_df[\"feature\"] = list(train_features)\n",
    "    imp_df[\"importance_gain\"] = clf.feature_importance(importance_type='gain')\n",
    "    imp_df[\"importance_split\"] = clf.feature_importance(importance_type='split')\n",
    "    imp_df['trn_score'] = roc_auc_score(y, clf.predict(data[train_features]))\n",
    "    \n",
    "    return imp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "continuous format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-f31e15daa67c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m123\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mactual_imp_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_feature_importances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-28-5e579b39b204>\u001b[0m in \u001b[0;36mget_feature_importances\u001b[0;34m(data, shuffle, seed)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mimp_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"importance_gain\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimportance_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gain'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mimp_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"importance_split\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimportance_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'split'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mimp_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'trn_score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimp_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr)\u001b[0m\n\u001b[1;32m    354\u001b[0m     return _average_binary_score(\n\u001b[1;32m    355\u001b[0m         \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/metrics/base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0my_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multilabel-indicator\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} format is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: continuous format is not supported"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "actual_imp_df = get_feature_importances(data=df_train, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_imp_df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_imp_df = pd.DataFrame()\n",
    "nb_runs = 80\n",
    "import time\n",
    "start = time.time()\n",
    "dsp = ''\n",
    "for i in range(nb_runs):\n",
    "    # Get current run importances\n",
    "    imp_df = get_feature_importances(data=data, shuffle=True)\n",
    "    imp_df['run'] = i + 1 \n",
    "    # Concat the latest importances with the old ones\n",
    "    null_imp_df = pd.concat([null_imp_df, imp_df], axis=0)\n",
    "    # Erase previous message\n",
    "    for l in range(len(dsp)):\n",
    "        print('\\b', end='', flush=True)\n",
    "    # Display current run and time used\n",
    "    spent = (time.time() - start) / 60\n",
    "    dsp = 'Done with %4d of %4d (Spent %5.1f min)' % (i + 1, nb_runs, spent)\n",
    "    print(dsp, end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_imp_df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_distributions(actual_imp_df_, null_imp_df_, feature_):\n",
    "    plt.figure(figsize=(13, 6))\n",
    "    gs = gridspec.GridSpec(1, 2)\n",
    "    # Plot Split importances\n",
    "    ax = plt.subplot(gs[0, 0])\n",
    "    a = ax.hist(null_imp_df_.loc[null_imp_df_['feature'] == feature_, 'importance_split'].values, label='Null importances')\n",
    "    ax.vlines(x=actual_imp_df_.loc[actual_imp_df_['feature'] == feature_, 'importance_split'].mean(), \n",
    "               ymin=0, ymax=np.max(a[0]), color='r',linewidth=10, label='Real Target')\n",
    "    ax.legend()\n",
    "    ax.set_title('Split Importance of %s' % feature_.upper(), fontweight='bold')\n",
    "    plt.xlabel('Null Importance (split) Distribution for %s ' % feature_.upper())\n",
    "    # Plot Gain importances\n",
    "    ax = plt.subplot(gs[0, 1])\n",
    "    a = ax.hist(null_imp_df_.loc[null_imp_df_['feature'] == feature_, 'importance_gain'].values, label='Null importances')\n",
    "    ax.vlines(x=actual_imp_df_.loc[actual_imp_df_['feature'] == feature_, 'importance_gain'].mean(), \n",
    "               ymin=0, ymax=np.max(a[0]), color='r',linewidth=10, label='Real Target')\n",
    "    ax.legend()\n",
    "    ax.set_title('Gain Importance of %s' % feature_.upper(), fontweight='bold')\n",
    "    plt.xlabel('Null Importance (gain) Distribution for %s ' % feature_.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_distributions(actual_imp_df_=actual_imp_df, null_imp_df_=null_imp_df, feature_='LIVINGAPARTMENTS_AVG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_distributions(actual_imp_df_=actual_imp_df, null_imp_df_=null_imp_df, feature_='CODE_GENDER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_scores = []\n",
    "for _f in actual_imp_df['feature'].unique():\n",
    "    f_null_imps_gain = null_imp_df.loc[null_imp_df['feature'] == _f, 'importance_gain'].values\n",
    "    f_act_imps_gain = actual_imp_df.loc[actual_imp_df['feature'] == _f, 'importance_gain'].mean()\n",
    "    gain_score = np.log(1e-10 + f_act_imps_gain / (1 + np.percentile(f_null_imps_gain, 75)))  # Avoid didvide by zero\n",
    "    f_null_imps_split = null_imp_df.loc[null_imp_df['feature'] == _f, 'importance_split'].values\n",
    "    f_act_imps_split = actual_imp_df.loc[actual_imp_df['feature'] == _f, 'importance_split'].mean()\n",
    "    split_score = np.log(1e-10 + f_act_imps_split / (1 + np.percentile(f_null_imps_split, 75)))  # Avoid didvide by zero\n",
    "    feature_scores.append((_f, split_score, gain_score))\n",
    "\n",
    "scores_df = pd.DataFrame(feature_scores, columns=['feature', 'split_score', 'gain_score'])\n",
    "\n",
    "plt.figure(figsize=(16, 16))\n",
    "gs = gridspec.GridSpec(1, 2)\n",
    "# Plot Split importances\n",
    "ax = plt.subplot(gs[0, 0])\n",
    "sns.barplot(x='split_score', y='feature', data=scores_df.sort_values('split_score', ascending=False).iloc[0:70], ax=ax)\n",
    "ax.set_title('Feature scores wrt split importances', fontweight='bold', fontsize=14)\n",
    "# Plot Gain importances\n",
    "ax = plt.subplot(gs[0, 1])\n",
    "sns.barplot(x='gain_score', y='feature', data=scores_df.sort_values('gain_score', ascending=False).iloc[0:70], ax=ax)\n",
    "ax.set_title('Feature scores wrt gain importances', fontweight='bold', fontsize=14)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_feature_selection(df=None, train_features=None, cat_feats=None, target=None):\n",
    "    # Fit LightGBM \n",
    "    dtrain = lgb.Dataset(df[train_features], target, free_raw_data=False, silent=True)\n",
    "    lgb_params = {\n",
    "        'objective': 'binary',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'learning_rate': .1,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'num_leaves': 31,\n",
    "        'max_depth': -1,\n",
    "        'seed': 13,\n",
    "        'n_jobs': 4,\n",
    "        'min_split_gain': .00001,\n",
    "        'reg_alpha': .00001,\n",
    "        'reg_lambda': .00001,\n",
    "        'metric': 'auc'\n",
    "    }\n",
    "    \n",
    "    # Fit the model\n",
    "    hist = lgb.cv(\n",
    "        params=lgb_params, \n",
    "        train_set=dtrain, \n",
    "        num_boost_round=2000,\n",
    "        categorical_feature=cat_feats,\n",
    "        nfold=5,\n",
    "        stratified=True,\n",
    "        shuffle=True,\n",
    "        early_stopping_rounds=50,\n",
    "        verbose_eval=0,\n",
    "        seed=17\n",
    "    )\n",
    "    # Return the last mean / std values \n",
    "    return hist['auc-mean'][-1], hist['auc-stdv'][-1]\n",
    "\n",
    "# features = [f for f in data.columns if f not in ['SK_ID_CURR', 'TARGET']]\n",
    "# score_feature_selection(df=data[features], train_features=features, target=data['TARGET'])\n",
    "\n",
    "for threshold in [0, 10, 20, 30 , 40, 50 ,60 , 70, 80 , 90, 95, 99]:\n",
    "    split_feats = [_f for _f, _score, _ in correlation_scores if _score >= threshold]\n",
    "    split_cat_feats = [_f for _f, _score, _ in correlation_scores if (_score >= threshold) & (_f in categorical_feats)]\n",
    "    gain_feats = [_f for _f, _, _score in correlation_scores if _score >= threshold]\n",
    "    gain_cat_feats = [_f for _f, _, _score in correlation_scores if (_score >= threshold) & (_f in categorical_feats)]\n",
    "                                                                                             \n",
    "    print('Results for threshold %3d' % threshold)\n",
    "    split_results = score_feature_selection(df=data, train_features=split_feats, cat_feats=split_cat_feats, target=data['TARGET'])\n",
    "    print('\\t SPLIT : %.6f +/- %.6f' % (split_results[0], split_results[1]))\n",
    "    gain_results = score_feature_selection(df=data, train_features=gain_feats, cat_feats=gain_cat_feats, target=data['TARGET'])\n",
    "    print('\\t GAIN  : %.6f +/- %.6f' % (gain_results[0], gain_results[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/c/elo-merchant-category-recommendation/discussion/75034"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/roydatascience/recursive-feature-selection-using-sklearn-on-elo?scriptVersionId=9969948"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "321.333px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
