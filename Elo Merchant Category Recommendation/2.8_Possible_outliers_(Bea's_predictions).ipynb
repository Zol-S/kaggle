{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To insert into section 1.4 of the final submision \n",
    "We recalculate some of the previous derived measures but using only the authorized transactions and the raw values of the purchase amounts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_trans = pd.concat([df_hist_trans, df_new_trans])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df_hist_trans\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_trans = df_all_trans[df_all_trans['authorized_flag']==1] #We will only use authorized transactions\n",
    "df_all_trans['purchase_amount_raw'] = df_all_trans['purchase_amount']/0.00150265118 + 497.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate for authorized transactions: number of transactions and merchants, and total raw amount\n",
    "agg_funcs_auth = {\n",
    "    'card_id': ['size'],\n",
    "    'merchant_id': ['nunique'],\n",
    "    'purchase_amount_raw': ['sum'],\n",
    "    'purchase_date': ['max']\n",
    "}\n",
    "df_agg_auth = df_all_trans.groupby('card_id').agg(agg_funcs_auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg_auth.columns = ['_'.join(col).strip() for col in df_agg_auth.columns.values]\n",
    "df_agg_auth.reset_index(drop=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Time up to May 1th, 2018\n",
    "df_agg_auth['last_date_upto_may'] = (datetime.datetime.strptime('May 1 2018', '%b %d %Y') - df_agg_auth['purchase_date_max']).dt.days\n",
    "df_agg_auth.drop('purchase_date_max', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_po = df_train.merge(df_agg_auth, on='card_id', how='left')\n",
    "df_test_po = df_test.merge(df_agg_auth, on='card_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_po.rename(columns={'card_id_size': 'n_purchase_amount', 'merchant_id_nunique': 'n_merchant', 'purchase_amount_raw_sum': 'sum_purchase_amount'}, inplace=True)\n",
    "df_test_po.rename(columns={'card_id_size': 'n_purchase_amount', 'merchant_id_nunique': 'n_merchant', 'purchase_amount_raw_sum': 'sum_purchase_amount'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df_agg_auth\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create year-month variable\n",
    "def create_date_year_month(df, source_column, preposition):\n",
    "    df[preposition + '_ym'] = df[source_column].dt.strftime('%Y') + '-' + df[source_column].dt.strftime('%m')    \n",
    "    return df\n",
    "df_all_trans = create_date_year_month(df_all_trans, 'purchase_date', 'purchase')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shape of the transactions over time\n",
    "def compute_shape(user):\n",
    "    grid = np.linspace(-1,1,user['purchase_ym'].nunique())\n",
    "    coeffs = np.polyfit(grid, user.groupby('purchase_ym')['purchase_amount_raw'].sum().values, 2)\n",
    "    return(pd.DataFrame({'purchase_shape': [np.sign(coeffs[0])]}))\n",
    "\n",
    "df_coeffs = df_all_trans.groupby('card_id')[['purchase_ym','purchase_amount_raw']].apply(compute_shape)\n",
    "df_coeffs = df_coeffs.reset_index(level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_po = df_train_po.merge(df_coeffs, on='card_id', how='left') \n",
    "df_test_po = df_test_po.merge(df_coeffs, on='card_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df_coeffs\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ratio max/median amount\n",
    "df_amounts_over_time = df_all_trans.groupby(['card_id','purchase_ym'])['purchase_amount_raw'].sum().reset_index()\n",
    "df_ratios = df_amounts_over_time.groupby('card_id')['purchase_amount_raw'].apply(lambda dfx: dfx.max() / dfx.median())\n",
    "df_ratios = df_ratios.reset_index(level=0)\n",
    "df_ratios.rename(columns={'purchase_amount_raw': 'ratio_amount'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_po = df_train_po.merge(df_ratios, on='card_id', how='left') \n",
    "df_test_po = df_test_po.merge(df_ratios, on='card_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df_amounts_over_time, df_ratios\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Time differences for favourite merchant\n",
    "def diff_times_fav(user):\n",
    "    id_merch_temp = user.groupby('merchant_id').size().idxmax()\n",
    "    dates_temp = user[user['merchant_id']==id_merch_temp].sort_values('purchase_date')['purchase_date'].values\n",
    "    diff_temp = (np.diff(dates_temp)/3.6e+12).astype(float)\n",
    "    return(pd.DataFrame({'diff_time_fav_mean': [diff_temp.mean()], 'diff_time_fav_std': [diff_temp.std()]}))\n",
    "\n",
    "df_diff_times = df_all_trans.groupby('card_id')[['merchant_id','purchase_date']].apply(diff_times_fav).reset_index(level=0)\n",
    "df_diff_times['diff_time_fav_mean'].fillna(0, inplace=True)\n",
    "df_diff_times['diff_time_fav_std'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_po = df_train_po.merge(df_diff_times, on='card_id', how='left') \n",
    "df_test_po = df_test_po.merge(df_diff_times, on='card_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df_diff_times\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Time differences for all transactions\n",
    "def diff_times(user):\n",
    "    diff_temp = (np.diff(np.sort(user.values))/3.6e+12).astype(float)\n",
    "    return(pd.DataFrame({'diff_time_mean': [diff_temp.mean()], 'diff_time_std': [diff_temp.std()]}))\n",
    "\n",
    "df_diff_times2 = df_all_trans.groupby('card_id')['purchase_date'].apply(diff_times).reset_index(level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_po = df_train_po.merge(df_diff_times2, on='card_id', how='left') \n",
    "df_test_po = df_test_po.merge(df_diff_times2, on='card_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df_diff_times2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If the user is in the new transactions set\n",
    "df_train_po['in_new'] = (df_train_po['card_id'].isin(df_new_trans['card_id'].values))*1\n",
    "df_test_po['in_new'] = (df_test_po['card_id'].isin(df_new_trans['card_id'].values))*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df_new_trans\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a perceptron with a single layer of 50 neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "X = df_train_po[['feature_1', 'feature_2', 'feature_3', 'n_purchase_amount',\n",
    "       'n_merchant', 'sum_purchase_amount', 'last_date_upto_may',\n",
    "       'purchase_shape', 'ratio_amount', 'diff_time_fav_mean',\n",
    "       'diff_time_fav_std', 'diff_time_mean', 'diff_time_std', 'in_new']]\n",
    "y = df_train_po['outliers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions for the train set with 5-folds\n",
    "os_smote = SMOTE(random_state=1)\n",
    "y_train_prob = np.zeros(y.shape[0])\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    #Over-sample the data\n",
    "    os_data_X, os_data_y = os_smote.fit_sample(X_train, y_train)\n",
    "    os_data_X = pd.DataFrame(data=os_data_X, columns=X_train.columns)\n",
    "    os_data_y= pd.DataFrame(data=os_data_y, columns=['y'])\n",
    "    \n",
    "    #Fit the MLPC\n",
    "    clf = MLPClassifier(hidden_layer_sizes=(50), max_iter=100, early_stopping=True, verbose=False,  random_state=1, tol=0.001)\n",
    "    clf.fit(os_data_X, os_data_y)\n",
    "    y_train_prob[test_index] = clf.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = 1*(y_train_prob>=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions for the test set\n",
    "\n",
    "#Over-sample the data\n",
    "os_data_X, os_data_y = os_smote.fit_sample(X, y)\n",
    "os_data_X = pd.DataFrame(data=os_data_X, columns=X.columns)\n",
    "os_data_y= pd.DataFrame(data=os_data_y, columns=['y'])\n",
    "    \n",
    "#Fit the MLPC\n",
    "clf = MLPClassifier(hidden_layer_sizes=(50), max_iter=100, early_stopping=True, verbose=False,  random_state=1, tol=0.001)\n",
    "clf.fit(os_data_X, os_data_y)\n",
    "\n",
    "#Predictions for the test set\n",
    "X_test = df_test_po[['feature_1', 'feature_2', 'feature_3', 'n_purchase_amount',\n",
    "       'n_merchant', 'sum_purchase_amount', 'last_date_upto_may',\n",
    "       'purchase_shape', 'ratio_amount', 'diff_time_fav_mean',\n",
    "       'diff_time_fav_std', 'diff_time_mean', 'diff_time_std', 'in_new']]\n",
    "y_test_prob = clf.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = 1*(y_test_prob >= 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store just the final predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_po['possible_out'] = y_train_pred\n",
    "df_test_po['possible_out'] = y_test_pred\n",
    "df_train = df_train.merge(df_train_po[['card_id','possible_out']], on='card_id', how='left')\n",
    "df_test = df_test.merge(df_test_po[['card_id','possible_out']], on='card_id', how='left')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
