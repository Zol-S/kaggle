{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elo Merchant Category Recommendation\n",
    "In this tutorial you can solve the [Elo Mechant Category Recommendation](https://www.kaggle.com/c/elo-merchant-category-recommendation) contest with the help of LynxKite. Unfortunately LynxKite does not yet support some of the data preprocessing, thus it needs to be done in Python.\n",
    "\n",
    "First download the input files from [here](https://www.kaggle.com/c/elo-merchant-category-recommendation/data), unzip them and copy the extracted files to the `input` folder. These files are\n",
    "\n",
    "- **train.csv**,  **test.csv**: list of `card_ids` that can be used for training and prediction\n",
    "- **historical_transactions.csv**: contains up to 3 months' worth of transactions for every card at any of the provided `merchant_ids`\n",
    "- **new_merchant_transactions.csv**: contains the transactions at new merchants (`merchant_ids` that this particular `card_id` \n",
    "has not yet visited) over a period of two months\n",
    "- **merchants.csv**: contains aggregate information for each `merchant_id` represented in the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import model_selection, preprocessing, metrics\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"output/train_preprocessed.csv\", index_col=0)\n",
    "df_test = pd.read_csv(\"output/test_preprocessed.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_active_month</th>\n",
       "      <th>card_id</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>target</th>\n",
       "      <th>feature_1_1</th>\n",
       "      <th>feature_1_2</th>\n",
       "      <th>feature_1_3</th>\n",
       "      <th>feature_1_4</th>\n",
       "      <th>feature_1_5</th>\n",
       "      <th>feature_2_1</th>\n",
       "      <th>...</th>\n",
       "      <th>hist_purchase_month_mean</th>\n",
       "      <th>hist_purchase_month_median</th>\n",
       "      <th>hist_purchase_month_max</th>\n",
       "      <th>hist_purchase_month_min</th>\n",
       "      <th>hist_purchase_month_std</th>\n",
       "      <th>hist_purchase_date_ptp</th>\n",
       "      <th>hist_purchase_date_min</th>\n",
       "      <th>hist_purchase_date_max</th>\n",
       "      <th>hist_month_lag_min</th>\n",
       "      <th>hist_month_lag_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>C_ID_92a2005557</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.8203</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.055</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3.475</td>\n",
       "      <td>20977988.0</td>\n",
       "      <td>1.498573e+09</td>\n",
       "      <td>1.519551e+09</td>\n",
       "      <td>-8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>C_ID_3d0044924f</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3928</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>6.220</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3.848</td>\n",
       "      <td>33717690.0</td>\n",
       "      <td>1.483720e+09</td>\n",
       "      <td>1.517438e+09</td>\n",
       "      <td>-12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>C_ID_d639edf6cd</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6880</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.560</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3.275</td>\n",
       "      <td>35635624.0</td>\n",
       "      <td>1.484123e+09</td>\n",
       "      <td>1.519758e+09</td>\n",
       "      <td>-13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  first_active_month          card_id  feature_3  target  feature_1_1  \\\n",
       "0         2017-06-01  C_ID_92a2005557          1 -0.8203            0   \n",
       "1         2017-01-01  C_ID_3d0044924f          0  0.3928            0   \n",
       "2         2016-08-01  C_ID_d639edf6cd          0  0.6880            0   \n",
       "\n",
       "   feature_1_2  feature_1_3  feature_1_4  feature_1_5  feature_2_1  \\\n",
       "0            0            0            0            1            0   \n",
       "1            0            0            1            0            1   \n",
       "2            1            0            0            0            0   \n",
       "\n",
       "          ...          hist_purchase_month_mean  hist_purchase_month_median  \\\n",
       "0         ...                             8.055                         8.0   \n",
       "1         ...                             6.220                         7.0   \n",
       "2         ...                             4.560                         4.0   \n",
       "\n",
       "   hist_purchase_month_max  hist_purchase_month_min  hist_purchase_month_std  \\\n",
       "0                       12                        1                    3.475   \n",
       "1                       12                        1                    3.848   \n",
       "2                       12                        1                    3.275   \n",
       "\n",
       "   hist_purchase_date_ptp  hist_purchase_date_min  hist_purchase_date_max  \\\n",
       "0              20977988.0            1.498573e+09            1.519551e+09   \n",
       "1              33717690.0            1.483720e+09            1.517438e+09   \n",
       "2              35635624.0            1.484123e+09            1.519758e+09   \n",
       "\n",
       "   hist_month_lag_min  hist_month_lag_max  \n",
       "0                  -8                   0  \n",
       "1                 -12                   0  \n",
       "2                 -13                   0  \n",
       "\n",
       "[3 rows x 109 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['first_active_year'] = pd.to_numeric(df_train['first_active_month'].str[:4])\n",
    "df_test['first_active_year'] = pd.to_numeric(df_test['first_active_month'].str[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_month(date_string):\n",
    "    o = 0\n",
    "    if (len(str(date_string)) == 10):\n",
    "        date = datetime.datetime.strptime(str(date_string), '%Y-%m-%d')\n",
    "        o = date.strftime(\"%m\")\n",
    "    return o\n",
    "\n",
    "df_train['first_active_month2'] = pd.to_numeric(df_train['first_active_month'].apply(lambda x: get_month(x)))\n",
    "df_test['first_active_month2'] = pd.to_numeric(df_test['first_active_month'].apply(lambda x: get_month(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df_train['target']\n",
    "drops = ['card_id', 'first_active_month', 'target']\n",
    "use_cols = [c for c in df_train.columns if c not in drops]\n",
    "features = list(df_train[use_cols].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LigthGBM\n",
    "For more details click [here](https://lightgbm.readthedocs.io/en/latest/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'num_leaves': 50,\n",
    "    'min_data_in_leaf': 30, \n",
    "    'objective':'regression',\n",
    "    'max_depth': -1,\n",
    "    'learning_rate': 0.005,\n",
    "    \"boosting\": \"gbdt\",\n",
    "    \"feature_fraction\": 0.9,\n",
    "    \"bagging_freq\": 1,\n",
    "    \"bagging_fraction\": 0.9,\n",
    "    \"bagging_seed\": 11,\n",
    "    \"metric\": 'rmse',\n",
    "    \"lambda_l1\": 0.1,\n",
    "    \"verbosity\": -1\n",
    "}\n",
    "\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=15)\n",
    "\n",
    "oof = np.zeros(len(df_train))\n",
    "predictions = np.zeros(len(df_test))\n",
    "\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(df_train.values, target.values)):\n",
    "    print('-')\n",
    "    print(\"Fold {}\".format(fold_ + 1))\n",
    "    trn_data = lgb.Dataset(df_train.iloc[trn_idx][features], label=target.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(df_train.iloc[val_idx][features], label=target.iloc[val_idx])\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=100, early_stopping_rounds=100)\n",
    "    oof[val_idx] = clf.predict(df_train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = features\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "    predictions += clf.predict(df_test[features], num_iteration=clf.best_iteration) / folds.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validation_lgb = np.sqrt(mean_squared_error(target, oof))\n",
    "print('Cross-validation score: ' + str(cross_validation_lgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = (feature_importance_df[[\"feature\", \"importance\"]]\n",
    "        .groupby(\"feature\")\n",
    "        .mean()\n",
    "        .sort_values(by=\"importance\", ascending=False)[:1000].index)\n",
    "\n",
    "best_features = feature_importance_df.loc[feature_importance_df['feature'].isin(cols)]\n",
    "\n",
    "plt.figure(figsize=(14, 25))\n",
    "sns.barplot(x=\"importance\",\n",
    "            y=\"feature\",\n",
    "            data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "plt.title('LightGBM Features (avg over folds)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('lgbm_importances.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(list(zip(clf.feature_importance(), features)), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = pd.DataFrame({\"card_id\":df_test[\"card_id\"].values})\n",
    "df_sub[\"target\"] = predictions\n",
    "df_sub.to_csv(\"output/lgbm_{}.csv\".format(cross_validation_lgb), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost\n",
    "For more details click [here](https://xgboost.readthedocs.io/en/latest/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Fold 1\n",
      "xgb 0--------------------------------------------------\n",
      "[0]\ttrain-rmse:3.93949\tvalid-rmse:3.98678\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 50 rounds.\n",
      "[1000]\ttrain-rmse:2.77727\tvalid-rmse:3.67839\n",
      "Stopping. Best iteration:\n",
      "[1045]\ttrain-rmse:2.75958\tvalid-rmse:3.6782\n",
      "\n",
      "-\n",
      "Fold 2\n",
      "xgb 1--------------------------------------------------\n",
      "[0]\ttrain-rmse:3.95974\tvalid-rmse:3.90617\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 50 rounds.\n",
      "[1000]\ttrain-rmse:2.78891\tvalid-rmse:3.63385\n",
      "Stopping. Best iteration:\n",
      "[1168]\ttrain-rmse:2.72379\tvalid-rmse:3.6333\n",
      "\n",
      "-\n",
      "Fold 3\n",
      "xgb 2--------------------------------------------------\n",
      "[0]\ttrain-rmse:3.96706\tvalid-rmse:3.87612\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[932]\ttrain-rmse:2.80842\tvalid-rmse:3.60703\n",
      "\n",
      "-\n",
      "Fold 4\n",
      "xgb 3--------------------------------------------------\n",
      "[0]\ttrain-rmse:3.91263\tvalid-rmse:4.09092\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 50 rounds.\n",
      "[1000]\ttrain-rmse:2.73531\tvalid-rmse:3.79945\n",
      "Stopping. Best iteration:\n",
      "[1021]\ttrain-rmse:2.72742\tvalid-rmse:3.79929\n",
      "\n",
      "-\n",
      "Fold 5\n",
      "xgb 4--------------------------------------------------\n",
      "[0]\ttrain-rmse:3.96391\tvalid-rmse:3.88822\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[727]\ttrain-rmse:2.9065\tvalid-rmse:3.63629\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_params = {\n",
    "    'eta': 0.005,\n",
    "    'max_depth': 10,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8, \n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'rmse',\n",
    "    'silent': True\n",
    "}\n",
    "\n",
    "#folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=15)\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=15)\n",
    "\n",
    "oof_xgb = np.zeros(len(df_train))\n",
    "predictions_xgb = np.zeros(len(df_test))\n",
    "\n",
    "feature_importance_xgb = pd.DataFrame()\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(df_train.values, target.values)):\n",
    "    print('-')\n",
    "    print(\"Fold {}\".format(fold_ + 1))\n",
    "    trn_data = xgb.DMatrix(data=df_train.iloc[trn_idx][features], label=target.iloc[trn_idx])\n",
    "    val_data = xgb.DMatrix(data=df_train.iloc[val_idx][features], label=target.iloc[val_idx])\n",
    "    watchlist = [(trn_data, 'train'), (val_data, 'valid')]\n",
    "    print(\"xgb \" + str(fold_) + \"-\" * 50)\n",
    "    num_round = 10000\n",
    "    xgb_model = xgb.train(xgb_params, trn_data, num_round, watchlist, early_stopping_rounds=50, verbose_eval=1000)\n",
    "    oof_xgb[val_idx] = xgb_model.predict(xgb.DMatrix(df_train.iloc[val_idx][features]), ntree_limit=xgb_model.best_ntree_limit+50)\n",
    "\n",
    "    fold_importance_xgb = pd.DataFrame()\n",
    "    fold_importance_xgb[\"feature\"] = features\n",
    "    #fold_importance_df[\"importance\"] = xgb_model.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_xgb, fold_importance_xgb], axis=0)\n",
    "    predictions_xgb += xgb_model.predict(xgb.DMatrix(df_test[features]), ntree_limit=xgb_model.best_ntree_limit+50) / folds.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation score: 3.67169630017\n"
     ]
    }
   ],
   "source": [
    "cross_validation_xgb = np.sqrt(mean_squared_error(target, oof_xgb))\n",
    "print('Cross-validation score: ' + str(cross_validation_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['importance'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-7782f7f4cdfc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m cols = (feature_importance_df[[\"feature\", \"importance\"]]\n\u001b[0m\u001b[1;32m      2\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"feature\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         .sort_values(by=\"importance\", ascending=False)[:1000].index)\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2680\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2681\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2682\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2683\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2684\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2724\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2725\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2726\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2727\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[1;32m   1325\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m                     raise KeyError('{mask} not in index'\n\u001b[0;32m-> 1327\u001b[0;31m                                    .format(mask=objarr[mask]))\n\u001b[0m\u001b[1;32m   1328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['importance'] not in index\""
     ]
    }
   ],
   "source": [
    "cols = (feature_importance_df[[\"feature\", \"importance\"]]\n",
    "        .groupby(\"feature\")\n",
    "        .mean()\n",
    "        .sort_values(by=\"importance\", ascending=False)[:1000].index)\n",
    "\n",
    "best_features = feature_importance_df.loc[feature_importance_df['feature'].isin(cols)]\n",
    "\n",
    "plt.figure(figsize=(14, 25))\n",
    "sns.barplot(x=\"importance\",\n",
    "            y=\"feature\",\n",
    "            data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "plt.title('XGBoost Features (avg over folds)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('xgboost_importances.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = pd.DataFrame({\"card_id\":df_test[\"card_id\"].values})\n",
    "df_sub[\"target\"] = predictions_xgb\n",
    "df_sub.to_csv(\"output/xgboost_{}.csv\".format(cross_validation_xgb), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
